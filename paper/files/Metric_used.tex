\subsubsection*{Metrics}

In this project, various metrics evaluate the heartbeat audio classification model, focusing on multiclass classification with imbalanced classes.

\paragraph{Accuracy}
Accuracy measures the ratio of correct predictions to the total number of predictions:
\[
    \text{Accuracy} = \frac{\text{Correct Predictions}}{\text{Total Predictions}}
\]
It is straightforward but can be misleading with imbalanced classes.

\paragraph{Balanced Accuracy}
Balanced accuracy addresses class imbalance by averaging recall across classes:
\[
    \text{Balanced Accuracy} = \frac{1}{N} \sum_{i=1}^{N} \frac{TP_i}{TP_i + FN_i}
\]
where \(N\) is the number of classes, \(TP_i\) is true positives, and \(FN_i\) is false negatives for class \(i\).

\paragraph{Matthews Correlation Coefficient (MCC)}
MCC evaluates performance by considering all classes:

\[
    \text{MCC} = \frac{\sum_k \sum_l \sum_m C_{kk} C_{lm} - C_{kl} C_{mk}}{\sqrt{\sum_k \left( \sum_l C_{kl} \right) \left( \sum_{k' \ne k} \sum_{l'} C_{k'l'} \right)} \sqrt{\sum_k \left( \sum_l C_{lk} \right) \left( \sum_{k' \ne k} \sum_{l'} C_{l'k'} \right)}}
\]
This comprehensive metric accounts for true and false predictions, making it robust for imbalanced datasets.

\paragraph{Precision and Recall}
Precision measures the accuracy of positive predictions:
\[
    \text{Precision} = \frac{TP}{TP + FP}
\]
Recall measures the proportion of actual positives correctly identified:
\[
    \text{Recall} = \frac{TP}{TP + FN}
\]
Micro variants aggregate these metrics across all classes, while macro variants average them per class, 
offering insights into individual class performance.

\paragraph{F1 Score}
The F1 score balances precision and recall:
\[
    \text{F1 Score} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
\]
Micro and macro variants provide overall and class-specific performance evaluations, respectively.

\paragraph{ROC Curve and AUC}
For binary classification, the ROC curve plots true positive rate against false positive rate, and AUC summarizes the model's discriminatory ability,
 with higher AUC indicating better performance.

\paragraph{Risk Score}
The risk score evaluates the model's ability to avoid misclassifying heart disease as normal:
\[
    \text{Risk score} = \frac{FP}{FP + TP}
\]
A lower risk score indicates better performance. Disease-specific risk scores can provide detailed insights into different heart conditions.