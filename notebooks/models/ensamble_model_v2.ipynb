{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score,balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-paper\")\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(context=\"paper\", font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the paths\n",
    "BASE_DIR = \"../../dataset/\"\n",
    "\n",
    "# features\n",
    "FEATURES_BASE = \"../../features/\"\n",
    "FEATURES = FEATURES_BASE + 'balanced/both/'\n",
    "\n",
    "# Models\n",
    "MODELS = \"../../models/\"\n",
    "MODELS_RESULTS = MODELS + \"results/\"\n",
    "\n",
    "# report\n",
    "PAPER = \"../../paper/\"\n",
    "IMAGES_PATH = PAPER + \"images/\"\n",
    "\n",
    "# HYERPARAMETERS\n",
    "SEED = 42\n",
    "INTERVAL = 2\n",
    "\n",
    "BALANCING_TYPE = \"both\"\n",
    "RESULT_NAME = f\"results_models_comparison_best_features_{BALANCING_TYPE}.csv\"\n",
    "CM_ARTIFACT_NAME = f\"confusion_matrix_models_comparison_artifact_recognition_{BALANCING_TYPE}.npy\"\n",
    "CM_DISEASE_NAME = (\n",
    "    f\"confusion_matrix_models_comparison_disease_recognition_{BALANCING_TYPE}.npy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------Constants-----------------------------------------\n",
    "full_data_dict_keys = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "interval = INTERVAL  # You need to define INTERVAL somewhere\n",
    "sample_rates = [4000]\n",
    "num_feats = {\n",
    "    \"30 MFCC\": \"25mfcc\",\n",
    "    \"12  Chroma\": \"12chroma\",\n",
    "    \"70 CQT\": \"1cqt\",\n",
    "    \"40 RMS\": \"0rms\",\n",
    "    \"40 Zero Crossing Rates\": \"1zcr\",\n",
    "    \"40 Spectral Centroid\": \"0sc\",\n",
    "    \"60 Spectral Bandwidth\": \"0sb\",\n",
    "    \"40 Spectral Rolloff\": \"0sr\",\n",
    "}\n",
    "\n",
    "COMPLETE_DATA_PRIOR_CORR_NAME = f'full_data_filtered_{INTERVAL}s_4000hz_' + '_'.join(numvalue for _, numvalue in num_feats.items()) + '.npy'\n",
    "# load the data\n",
    "full_data = np.load(FEATURES + COMPLETE_DATA_PRIOR_CORR_NAME, allow_pickle=True).item()\n",
    "n_cols = full_data['train']['X'].shape[1]\n",
    "\n",
    "# Extract data from the dictionary\n",
    "X_train = full_data[\"train\"][\"X\"]\n",
    "y_train = full_data[\"train\"][\"y\"]\n",
    "X_test = full_data[\"test\"][\"X\"]\n",
    "y_test = full_data[\"test\"][\"y\"]\n",
    "y_train[y_train != 0] = 1\n",
    "y_test[y_test != 0] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Artifact recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest\n",
      "\tCalculating Test Acc\n",
      "\tCalculating Macro F1\n",
      "\tCalculating Balanced Accuracy\n",
      "\n",
      "Training XGBoost\n",
      "\tCalculating Test Acc\n",
      "\tCalculating Macro F1\n",
      "\tCalculating Balanced Accuracy\n",
      "\n",
      "Training MLP\n",
      "\tCalculating Test Acc\n",
      "\tCalculating Macro F1\n",
      "\tCalculating Balanced Accuracy\n",
      "\n",
      "Training CatBoost\n",
      "\tCalculating Test Acc\n",
      "\tCalculating Macro F1\n",
      "\tCalculating Balanced Accuracy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.977451</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.985915</td>\n",
       "      <td>0.977451</td>\n",
       "      <td>0.964912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.984155</td>\n",
       "      <td>0.97472</td>\n",
       "      <td>0.963811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.987676</td>\n",
       "      <td>0.980338</td>\n",
       "      <td>0.969298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Test Acc  Macro F1 Balanced Accuracy\n",
       "Random Forest  0.985915  0.977451          0.964912\n",
       "XGBoost        0.985915  0.977451          0.964912\n",
       "MLP            0.984155   0.97472          0.963811\n",
       "CatBoost       0.987676  0.980338          0.969298"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------------------- Create DataFrame to store results-----------------------------------------\n",
    "MODELS = {'Random Forest': RandomForestClassifier(random_state=SEED),\n",
    "        'XGBoost': XGBClassifier(random_state=SEED),\n",
    "        'MLP': MLPClassifier(hidden_layer_sizes=(128, 64, 32,), activation='relu', solver='adam', random_state=SEED),\n",
    "        'CatBoost': CatBoostClassifier(random_state=SEED, verbose=0),}\n",
    "\n",
    "METRICS = {\n",
    "    \"Test Acc\": accuracy_score,\n",
    "    \"Macro F1\": f1_score,\n",
    "    \"Balanced Accuracy\": balanced_accuracy_score,\n",
    "}\n",
    "\n",
    "result_df = pd.DataFrame(columns=list(METRICS.keys()), index=list(MODELS.keys()))\n",
    "cm_dict = {}\n",
    "\n",
    "# ----------------------------------------- Loop over each feature-----------------------------------------\n",
    "for model_name, clf in MODELS.items():\n",
    "    print(f\"\\nTraining {model_name}\")\n",
    "\n",
    "\n",
    "    # fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    for metric, funct in METRICS.items():\n",
    "        print(f\"\\tCalculating {metric}\")\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        if \"Macro\" in metric:\n",
    "                result_df.loc[model_name, metric] = funct(y_test, y_pred, average='macro')\n",
    "        else:\n",
    "                result_df.loc[model_name, metric] = funct(y_test, y_pred)\n",
    "        # cf\n",
    "        cf = confusion_matrix(y_test, y_pred)\n",
    "        cm_dict[model_name] = cf\n",
    "\n",
    "# ----------------------------------------- Save the results-----------------------------------------\n",
    "result_df.to_csv(MODELS_RESULTS + RESULT_NAME)\n",
    "np.save(MODELS_RESULTS + CM_ARTIFACT_NAME, cm_dict)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7e4cdcf7ee70>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_artifact_model = CatBoostClassifier(random_state=SEED, verbose=0)\n",
    "best_artifact_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart disease prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Random Forest\n",
      "\tCalculating Test Acc\n",
      "\tCalculating Macro F1\n",
      "\tCalculating Balanced Accuracy\n",
      "\n",
      "Training XGBoost\n",
      "\tCalculating Test Acc\n",
      "\tCalculating Macro F1\n",
      "\tCalculating Balanced Accuracy\n",
      "\n",
      "Training MLP\n",
      "\tCalculating Test Acc\n",
      "\tCalculating Macro F1\n",
      "\tCalculating Balanced Accuracy\n",
      "\n",
      "Training CatBoost\n",
      "\tCalculating Test Acc\n",
      "\tCalculating Macro F1\n",
      "\tCalculating Balanced Accuracy\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Test Acc</th>\n",
       "      <th>Macro F1</th>\n",
       "      <th>Balanced Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.843612</td>\n",
       "      <td>0.844835</td>\n",
       "      <td>0.816424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.854626</td>\n",
       "      <td>0.857045</td>\n",
       "      <td>0.838387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MLP</th>\n",
       "      <td>0.861233</td>\n",
       "      <td>0.86682</td>\n",
       "      <td>0.865041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost</th>\n",
       "      <td>0.865639</td>\n",
       "      <td>0.870926</td>\n",
       "      <td>0.848684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Test Acc  Macro F1 Balanced Accuracy\n",
       "Random Forest  0.843612  0.844835          0.816424\n",
       "XGBoost        0.854626  0.857045          0.838387\n",
       "MLP            0.861233   0.86682          0.865041\n",
       "CatBoost       0.865639  0.870926          0.848684"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract data from the dictionary\n",
    "full_data = np.load(FEATURES + COMPLETE_DATA_PRIOR_CORR_NAME, allow_pickle=True).item()\n",
    "n_cols = full_data[\"train\"][\"X\"].shape[1]\n",
    "\n",
    "# Extract data from the dictionary\n",
    "X_train = full_data[\"train\"][\"X\"]\n",
    "y_train = full_data[\"train\"][\"y\"]\n",
    "X_test = full_data[\"test\"][\"X\"]\n",
    "y_test = full_data[\"test\"][\"y\"]\n",
    "X_train = full_data[\"train\"][\"X\"]\n",
    "y_train = full_data[\"train\"][\"y\"].reshape(-1)\n",
    "X_test = full_data[\"test\"][\"X\"]\n",
    "y_test = full_data[\"test\"][\"y\"]\n",
    "train_mask = y_train != 0\n",
    "test_mask = y_test != 0\n",
    "\n",
    "X_train = X_train[train_mask]\n",
    "y_train = y_train[train_mask]\n",
    "X_test = X_test[test_mask]\n",
    "y_test = y_test[test_mask]\n",
    "\n",
    "y_train = y_train - 1\n",
    "y_test = y_test - 1\n",
    "result_df = pd.DataFrame(columns=list(METRICS.keys()), index=list(MODELS.keys()))\n",
    "cm_dict = {}\n",
    "\n",
    "# ----------------------------------------- Loop over each feature-----------------------------------------\n",
    "for model_name, clf in MODELS.items():\n",
    "    print(f\"\\nTraining {model_name}\")\n",
    "\n",
    "    # fit the model\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    for metric, funct in METRICS.items():\n",
    "        print(f\"\\tCalculating {metric}\")\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        if \"Macro\" in metric:\n",
    "            result_df.loc[model_name, metric] = funct(y_test, y_pred, average=\"macro\")\n",
    "        else:\n",
    "            result_df.loc[model_name, metric] = funct(y_test, y_pred)\n",
    "        # cf\n",
    "        cf = confusion_matrix(y_test, y_pred)\n",
    "        cm_dict[model_name] = cf\n",
    "\n",
    "# ----------------------------------------- Save the results-----------------------------------------\n",
    "result_df.to_csv(MODELS_RESULTS + RESULT_NAME)\n",
    "np.save(MODELS_RESULTS + CM_DISEASE_NAME, cm_dict)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7e4cddf52120>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_disease_model = CatBoostClassifier(random_state=SEED, verbose=0)\n",
    "best_disease_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SOluzione Semplice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact_pred shape: (568,)\n",
      "disease_pred shape: (568,)\n",
      "y_pred shape: (568,)\n",
      "F1 Score: 0.8845618939562814\n",
      "Accuracy Score: 0.8802816901408451\n",
      "Balanced Accuracy Score: 0.8666662415234828\n"
     ]
    }
   ],
   "source": [
    "def predict(artifact_model, disease_model, X):\n",
    "    # Predict artifacts (0 for artifact, 1 for not an artifact)\n",
    "    artifact_pred = artifact_model.predict(X)\n",
    "\n",
    "    # Predict disease (assuming output is an integer class label 0, 1, 2 for diseases)\n",
    "    disease_pred = disease_model.predict(X)\n",
    "\n",
    "    # Ensure disease predictions are reshaped to match artifact predictions\n",
    "    disease_pred = disease_pred.flatten()\n",
    "\n",
    "    # Add 1 to disease predictions to differentiate disease classes from artifact class\n",
    "    y_pred = disease_pred + 1\n",
    "\n",
    "    # Multiply by artifact predictions to set disease predictions to 0 for artifacts\n",
    "    y_pred = y_pred * artifact_pred\n",
    "\n",
    "    print(f\"artifact_pred shape: {artifact_pred.shape}\")\n",
    "    print(f\"disease_pred shape: {disease_pred.shape}\")\n",
    "    print(f\"y_pred shape: {y_pred.shape}\")\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Extract data from the dictionary\n",
    "full_data = np.load(FEATURES + COMPLETE_DATA_PRIOR_CORR_NAME, allow_pickle=True).item()\n",
    "n_cols = full_data[\"train\"][\"X\"].shape[1]\n",
    "\n",
    "# Extract data from the dictionary\n",
    "X_train = full_data[\"train\"][\"X\"]\n",
    "y_train = full_data[\"train\"][\"y\"]\n",
    "X_test = full_data[\"test\"][\"X\"]\n",
    "y_test = full_data[\"test\"][\"y\"]\n",
    "\n",
    "\n",
    "y_pred = predict(best_artifact_model, best_disease_model, X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy Score: {accuracy}\")\n",
    "print(f\"Balanced Accuracy Score: {balanced_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uso un terzo modello per predire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.8845618939562814\n",
      "Accuracy Score: 0.8802816901408451\n",
      "Balanced Accuracy Score: 0.8666662415234828\n"
     ]
    }
   ],
   "source": [
    "# Extract data from the dictionary\n",
    "full_data = np.load(FEATURES + COMPLETE_DATA_PRIOR_CORR_NAME, allow_pickle=True).item()\n",
    "n_cols = full_data[\"train\"][\"X\"].shape[1]\n",
    "\n",
    "# Extract data from the dictionary\n",
    "X_train = full_data[\"train\"][\"X\"]\n",
    "y_train = full_data[\"train\"][\"y\"]\n",
    "X_test = full_data[\"test\"][\"X\"]\n",
    "y_test = full_data[\"test\"][\"y\"]\n",
    "\n",
    "\n",
    "# Predictions for training data\n",
    "pred_artifact_train = best_artifact_model.predict(X_train)\n",
    "pred_disease_train = best_disease_model.predict(X_train)\n",
    "pred_artifact_test = best_artifact_model.predict(X_test)\n",
    "pred_disease_test = best_disease_model.predict(X_test)\n",
    "\n",
    "# Concatenate predictions to form new feature set\n",
    "X_train_new = np.concatenate(\n",
    "    (pred_artifact_train.reshape(-1, 1), pred_disease_train.reshape(-1, 1)), axis=1\n",
    ")\n",
    "\n",
    "X_test_new = np.concatenate(\n",
    "    (pred_artifact_test.reshape(-1, 1), pred_disease_test.reshape(-1, 1)), axis=1\n",
    ")\n",
    "\n",
    "# Train the final model\n",
    "last_model = CatBoostClassifier(random_state=SEED, verbose=0)\n",
    "last_model.fit(X_train_new, y_train)\n",
    "\n",
    "# Predict using the final model\n",
    "y_pred = last_model.predict(X_test_new)\n",
    "\n",
    "# Calculate and print metrics\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Accuracy Score: {accuracy}\")\n",
    "print(f\"Balanced Accuracy Score: {balanced_accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
