{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balancing Impact Notebook\n",
    "\n",
    "---\n",
    "\n",
    "### Objective:\n",
    "\n",
    "- Given the chosen sampling rate, extraction interval and selected features, to assess the impact of different balancing strategies on the performance of the model.\n",
    "- To determine the optimal balancing strategies for the model.\n",
    "\n",
    "### Methodology:\n",
    "\n",
    "- A model (RF, SVM, LR) is trained with selected features.\n",
    "- The model is trained with 80% of the data and tested with the remaining 20%.\n",
    "\n",
    "#### Findings:\n",
    "\n",
    "Selected Features prior to the correlation analysis:\n",
    "\n",
    "| Type                | NÂ° Features |\n",
    "| ------------------- | ---------- |\n",
    "| MFCC                | 30         |\n",
    "| CQT                 | 70         |\n",
    "| Chroma              | 12         |\n",
    "| RMS                 | 40         |\n",
    "| Zero Crossing Rates | 40         |\n",
    "| Spectral Centroid   | 40         |\n",
    "| Spectral Bandwidth  | 60         |\n",
    "| Spectral Rolloff    | 40         |\n",
    "\n",
    "\n",
    "Selected Features after the correlation analysis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8-paper\")\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme(context=\"paper\", font_scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the paths\n",
    "BASE_DIR = \"../../dataset/\"\n",
    "LABELS = BASE_DIR + \"labels.csv\"\n",
    "\n",
    "# features\n",
    "FEATURES_BASE = \"../../features/\"\n",
    "#FEATURES = FEATURES_BASE + \"raw/\"\n",
    "#FEATURES = FEATURES_BASE + 'balanced/posteriori/'\n",
    "#FEATURES = FEATURES_BASE + 'balanced/priori/'\n",
    "FEATURES = FEATURES_BASE + 'balanced/both/'\n",
    "\n",
    "# Models\n",
    "MODELS = \"../../models/\"\n",
    "MODELS_RESULTS = MODELS + \"results/\"\n",
    "\n",
    "# report\n",
    "PAPER = \"../../paper/\"\n",
    "IMAGES_PATH = PAPER + \"images/\"\n",
    "\n",
    "# HYERPARAMETERS\n",
    "SEED = 42\n",
    "INTERVAL = 2\n",
    "\n",
    "RESULT_NAME = \"results_balancing_comparison.csv\"\n",
    "BALANCING_TYPE = \"priori\"\n",
    "COMPLETE_DATA_PRIOR_CORR_NAME = f'full_data_{BALANCING_TYPE}_bal_{INTERVAL}s_4000hz_30mfcc_12chroma_70cqt_41rms_41zcr_41sc_61sb_41sr.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------Constants-----------------------------------------\n",
    "SEED = 42\n",
    "full_data_dict_keys = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "interval = INTERVAL  # You need to define INTERVAL somewhere\n",
    "sample_rates = [\"mix\", 4000]\n",
    "num_feats = {\n",
    "    \"30 MFCC\": \"30mfcc\",\n",
    "    \"12  Chroma\": \"12chroma\",\n",
    "    \"70 CQT\": \"70cqt\",\n",
    "    \"40 RMS\": \"41rms\",\n",
    "    \"40 Zero Crossing Rates\": \"41zcr\",\n",
    "    \"40 Spectral Centroid\": \"41sc\",\n",
    "    \"60 Spectral Bandwidth\": \"61sb\",\n",
    "    \"40 Spectral Rolloff\": \"41sr\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 4000hz_30mfcc\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'artifacts'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m y_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m full_data_dict_keys:\n\u001b[0;32m---> 16\u001b[0m      X \u001b[38;5;241m=\u001b[39m \u001b[43mfull_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m# (n_samples_class_key, num_feat)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m      y \u001b[38;5;241m=\u001b[39m full_data[key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;66;03m# (n_samples_class_key,)\u001b[39;00m\n\u001b[1;32m     18\u001b[0m      X_list\u001b[38;5;241m.\u001b[39mappend(X) \n",
      "\u001b[0;31mKeyError\u001b[0m: 'artifacts'"
     ]
    }
   ],
   "source": [
    "# create a unique dataset\n",
    "full_X = []\n",
    "full_y = []\n",
    "for name,num_feat in num_feats.items():\n",
    "     print(f\"Processing 4000hz_{num_feat}\")\n",
    "\n",
    "     # Load the data\n",
    "     FEATURES_NAME = f\"full_data_{interval}s_4000hz_{num_feat}.npy\"\n",
    "     full_data = np.load(FEATURES + FEATURES_NAME, allow_pickle=True).item()\n",
    "\n",
    "     # Extract data from the dictionary\n",
    "     data_list = []\n",
    "     X_list = []\n",
    "     y_list = []\n",
    "     for key in full_data_dict_keys:\n",
    "          X = full_data[key][\"X\"] # (n_samples_class_key, num_feat)\n",
    "          y = full_data[key][\"y\"] # (n_samples_class_key,)\n",
    "          X_list.append(X) \n",
    "          y_list.append(y)\n",
    "     full_X.append(np.concatenate(X_list, axis=0)) # (n_samples, num_feat)\n",
    "     full_y = np.concatenate(y_list, axis=0) # (n_samples,)\n",
    "     print(f\"Shape of X: {full_X[-1].shape}\\n\")\n",
    "features = np.hstack(full_X) # (n_samples, num_feats_total)\n",
    "\n",
    "# Concatenate all the features\n",
    "full_data_array = np.hstack((features, full_y.reshape(-1, 1)))\n",
    "print(f\"Shape of full_data_array: {full_data_array.shape}\")\n",
    "\n",
    "# split the data\n",
    "X = full_data_array[:, :-1]\n",
    "y = full_data_array[:, -1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED)\n",
    "\n",
    "# create the full dict\n",
    "full_dict = {\n",
    "     'train' : {\n",
    "     'X' : X_train,\n",
    "     'y' : y_train\n",
    "},\n",
    "     'test' : {\n",
    "     'X' : X_test,\n",
    "     'y' : y_test\n",
    "}\n",
    "}\n",
    "\n",
    "# save the data\n",
    "np.save(FEATURES + COMPLETE_DATA_PRIOR_CORR_NAME, full_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------- Create DataFrame to store results-----------------------------------------\n",
    "balancing_types = [\"none\", \"priori\", \"posteriori\", \"both\"]\n",
    "result_df = pd.DataFrame(\n",
    "    columns=balancing_types,\n",
    "    index=[\"Random Forest\", \"SVM\", \"Logistic Regression\"],\n",
    ")\n",
    "\n",
    "# ----------------------------------------- Loop over each feature-----------------------------------------\n",
    "for type_ in balancing_types:\n",
    "\n",
    "    # Load the data\n",
    "    FEATURES_NAME = f'full_data_{type_}_bal_{INTERVAL}s_4000hz_30mfcc_12chroma_70cqt_41rms_41zcr_41sc_61sb_41sr.npy'\n",
    "    full_data = np.load(FEATURES + FEATURES_NAME, allow_pickle=True).item()\n",
    "\n",
    "    # Extract data from the dictionary\n",
    "    X_train = full_data[\"train\"][\"X\"]\n",
    "    y_train = full_data[\"train\"][\"y\"]\n",
    "    X_test = full_data[\"test\"][\"X\"]\n",
    "    y_test = full_data[\"test\"][\"y\"]\n",
    "\n",
    "    # Train and evaluate models: Random Forest, SVM, Logistic Regression\n",
    "    for model_name, clf in {\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=SEED),\n",
    "        \"SVM\": SVC(random_state=SEED),\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=SEED, max_iter=1000),\n",
    "    }.items():\n",
    "        print(f\"Training {model_name}\\n\")\n",
    "        clf.fit(X_train, y_train)\n",
    "        score = clf.score(X_test, y_test)\n",
    "        result_df.loc[model_name, type_] = score\n",
    "\n",
    "# ----------------------------------------- Save the results-----------------------------------------\n",
    "result_df.to_csv(MODELS_RESULTS + RESULT_NAME)\n",
    "result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv(MODELS_RESULTS + RESULT_NAME, index_col=0).transpose()\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "sns.set_theme(context=\"paper\", font_scale=1)\n",
    "\n",
    "sns.heatmap(result_df.astype(float) * 100, annot=True, cmap=\"vlag\", fmt=\".2f\",vmax=100,vmin=0,linewidths=0.5)\n",
    "plt.title(\"Accuracy (%)\", fontsize=14)\n",
    "plt.xlabel(\"Models\", fontsize=12)\n",
    "plt.yticks(rotation=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
