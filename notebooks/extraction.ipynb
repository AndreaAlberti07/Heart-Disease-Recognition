{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Notebook\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is used to extract features from the data. The audio is divided into windows of 1 second. The features extracted from each audio window are:\n",
    "\n",
    "- **MFCC (Mel-Frequency Cepstral Coefficients)**: n_mfcc chosen by the user\n",
    "- **Chroma STFT**: 12 coefficients\n",
    "- **CQT (Constant-Q Transform)**: n_cqt chosen by the user\n",
    "- **RMS (Root Mean Square) Energy**: 1 coefficient\n",
    "- **Spectral Centroid**: 1 coefficient\n",
    "- **Spectral Bandwidth**: 1 coefficient\n",
    "- **Spectral Roll-off**: 1 coefficient\n",
    "- **Zero Crossing Rate**: 1 coefficient\n",
    "\n",
    "#### Sections:\n",
    "\n",
    "- [Feature Extraction](#Feature-Extraction)\n",
    "  - [Specific Features Extraction](#Specific-Features-Extraction)\n",
    "  - [All Features Extraction](#All-Features-Extraction)\n",
    "\n",
    "#### Findings:\n",
    "\n",
    "- We have highly unbalanced classes in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/andreaalberti/Desktop/Public_Projects/advanced-biomedical-project/notebooks/utils.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import all the functions\n",
    "import utils as utils\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import importlib\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "# import the utils module\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n",
       "\n",
       "# -------- tqdm DARK THEME --------\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>\n",
    "\n",
    "# -------- tqdm DARK THEME --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "#sr = 'mix'\n",
    "sr = 4000\n",
    "INTERVAL = 1\n",
    "\n",
    "# set the paths to data\n",
    "BASE_DIR = \"../dataset/\"\n",
    "ARTIFACTS_DIR = BASE_DIR + f\"artifacts_{sr}/\"\n",
    "EXTRAHLS_DIR = BASE_DIR + f\"extrahls_{sr}/\"\n",
    "MURMURS_DIR = BASE_DIR + f\"murmurs_{sr}/\"\n",
    "NORMALS_DIR = BASE_DIR + f\"normals_{sr}/\"\n",
    "EXTRASTOLES_DIR = BASE_DIR + f\"extrastoles_{sr}/\"\n",
    "\n",
    "# paths to save the features\n",
    "#FEATURES_RAW_DIR = \"../features/raw/\"\n",
    "FEATURES_RAW_DIR = \"../features/balanced/priori/\"\n",
    "#FEATURES_RAW_DIR = \"../features/balanced/posteriori/\"\n",
    "#FEATURES_RAW_DIR = \"../features/balanced/both/\"\n",
    "\n",
    "PATHS = [ARTIFACTS_DIR, EXTRAHLS_DIR, MURMURS_DIR, NORMALS_DIR, EXTRASTOLES_DIR]\n",
    "\n",
    "# # REMOVE THE AUGEMENTED SAMPLES WHEN EXTRACTING BASE RAW FEATURES\n",
    "# for path in PATHS:\n",
    "#      utils.remove_generated_samples(path, 'USERAUGMENTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<enumerate object at 0x2921c3510>\n"
     ]
    }
   ],
   "source": [
    "print(enumerate(PATHS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Features Extraction\n",
    "\n",
    "- **MFCC (Mel-Frequency Cepstral Coefficients)**: n_mfcc chosen by the user\n",
    "- **Chroma STFT**: 12 coefficients\n",
    "- **CQT (Constant-Q Transform)**: n_cqt chosen by the user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(\n",
    "    dir_path: str,\n",
    "    label: str,\n",
    "    extraction_interval: float,\n",
    "    sample_rate: int = 44100,\n",
    "    n_mfcc: int = 13,\n",
    "    melkwargs: dict = {},\n",
    "    n_cqt: int = 84,\n",
    "    n_rms: int = 20,\n",
    "    n_zcr: int = 20,\n",
    "    n_sc: int = 20,\n",
    "    n_sb: int = 20, \n",
    "    n_sr: int = 20,\n",
    "    get_mfcc: bool = False,\n",
    "    get_chroma: bool = False,\n",
    "    get_cqt: bool = False,\n",
    "    get_rms: bool = False,\n",
    "    get_zcr: bool = False,\n",
    "    get_sc: bool = False,\n",
    "    get_sb: bool = False,\n",
    "    get_sr: bool = False,\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Extracts audio features (MFCC, chroma, RMS, spectral centroid, spectral bandwidth, spectral rolloff, zero-crossing rate)\n",
    "    from audio files in the specified directory.\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): The path to the directory containing audio files.\n",
    "        label (str): The label associated with the extracted features.\n",
    "        extraction_interval: The frame length for feature extraction.\n",
    "        sample_rate (int, optional): The sample rate of the audio files. Defaults to 44100 Hz.\n",
    "        n_mfcc (int, optional): The number of Mel-frequency cepstral coefficients (MFCCs) to extract. Defaults to 13.\n",
    "        melkwargs (dict, optional): Additional arguments for Mel spectrogram computation.\n",
    "        n_cqt (int, optional): The number of constant-Q transform (CQT) bins to extract. Defaults to 84.\n",
    "        n_rms (int, optional): The number of RMS values to extract. Defaults to 20.\n",
    "        n_zcr (int, optional): The number of zero-crossing rate values to extract. Defaults to 20.\n",
    "        n_sc (int, optional): The number of spectral centroid values to extract. Defaults to 20.\n",
    "        n_sb (int, optional): The number of spectral bandwidth values to extract. Defaults to 20.\n",
    "        n_sr (int, optional): The number of spectral rolloff values to extract. Defaults to 20.\n",
    "        get_mfcc (bool, optional): Whether to extract MFCC features. Defaults to False.\n",
    "        get_chroma (bool, optional): Whether to extract chroma features. Defaults to False.\n",
    "        get_cqt (bool, optional): Whether to extract CQT features. Defaults to False.\n",
    "        get_rms (bool, optional): Whether to extract RMS features. Defaults to False.\n",
    "        get_zcr (bool, optional): Whether to extract zero-crossing rate features. Defaults to False.\n",
    "        get_sc (bool, optional): Whether to extract spectral centroid features. Defaults to False.\n",
    "        get_sb (bool, optional): Whether to extract spectral bandwidth features. Defaults to False.\n",
    "        get_sr (bool, optional): Whether to extract spectral rolloff features. Defaults to False.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        list: A list containing tensors of extracted features for each audio file.\n",
    "    \"\"\"\n",
    "    filenames = os.listdir(dir_path)\n",
    "    filenames = [file for file in filenames if not file.startswith(\".\")]\n",
    "    #filenames = [file for file in filenames if 'USERAUGMENTED' in file] FOR DATA AUGMENTATION\n",
    "    \n",
    "    if filenames == []:\n",
    "        print(f\"No files found in {dir_path}. Exiting...\")\n",
    "        return 200\n",
    "    \n",
    "    extraction_interval = 1 / extraction_interval\n",
    "\n",
    "    features = []  # List to store the features for all files\n",
    "\n",
    "    for file in tqdm(filenames, desc=f\"Extraction in progress\"):\n",
    "        audio, orig_sample_rate = torchaudio.load(os.path.join(dir_path, file))\n",
    "        orig_sample_rate_tmp = int(orig_sample_rate / extraction_interval)\n",
    "        audio_length = int(max(audio[0].shape) / (orig_sample_rate_tmp))\n",
    "\n",
    "        sample_rate = orig_sample_rate\n",
    "\n",
    "        # Reduce the audio from stereo to mono if needed\n",
    "        if audio.shape[0] > 1:\n",
    "            print(f\"Converting stereo audio to mono for {file}...\")\n",
    "            audio = torch.mean(audio, dim=0).reshape(1, -1)\n",
    "\n",
    "        features_local = []  # List to store the MFCC features for each file\n",
    "\n",
    "        for i in range(audio_length):\n",
    "            # Lazy load the audio, one sec at a time, to avoid memory issues\n",
    "            audio_mono = utils.slicing(\n",
    "                audio,\n",
    "                offset=int(sample_rate / extraction_interval * i),\n",
    "                num_frames=int(sample_rate / extraction_interval * (i + 1)),\n",
    "            )\n",
    "\n",
    "            # Get the MFCC features\n",
    "            if get_mfcc:\n",
    "                mfcc_features_tmp = utils.extract_mfcc(\n",
    "                    audio_mono, sample_rate, n_mfcc, melkwargs\n",
    "                )\n",
    "            if get_chroma:\n",
    "                chroma_stft = utils.extract_chroma_stft(audio_mono, sample_rate)\n",
    "            if get_cqt:\n",
    "                cqt = utils.extract_cqt(\n",
    "                    audio_mono, sample_rate=sample_rate, n_cqt=n_cqt\n",
    "                )\n",
    "            if get_rms:\n",
    "                rms = extract_rms(audio_mono, num_values=n_rms)\n",
    "            if get_zcr:\n",
    "                zcr = extract_zero_crossing_rate(audio_mono, num_values=n_zcr)\n",
    "            if get_sc:\n",
    "                spec_cent = extract_spectral_centroid(audio_mono, sample_rate, num_values=n_sc)\n",
    "            if get_sb:\n",
    "                spec_bw = extract_spectral_bandwidth(audio_mono, sample_rate, num_values=n_sb)\n",
    "            if get_sr:\n",
    "                rolloff = extract_spectral_rolloff(audio_mono, sample_rate, num_values=n_sr)\n",
    "\n",
    "            #   spec_cent = extract_spectral_centroid(audio_mono, sample_rate)\n",
    "            #   spec_bw = extract_spectral_bandwidth(audio_mono, sample_rate)\n",
    "            #   rolloff = extract_spectral_rolloff(audio_mono, sample_rate)\n",
    "            #   zcr = extract_zero_crossing_rate(audio_mono)\n",
    "\n",
    "            # check that no more than one feature is extracted. Else raise an error\n",
    "            if sum([get_mfcc, get_chroma, get_cqt, get_rms, get_zcr, get_sc, get_sb, get_sr]) != 1:\n",
    "                raise ValueError(\n",
    "                    \"Exactly one feature must be extracted at a time. Please check the arguments.\"\n",
    "                )\n",
    "            \n",
    "            # Concatenate the features\n",
    "            if get_mfcc:\n",
    "                features_tmp = mfcc_features_tmp\n",
    "            if get_chroma:\n",
    "                features_tmp = chroma_stft\n",
    "            if get_cqt:\n",
    "                features_tmp = cqt\n",
    "            if get_rms:\n",
    "                features_tmp = rms\n",
    "            if get_zcr:\n",
    "                features_tmp = zcr\n",
    "            if get_sc:\n",
    "                features_tmp = spec_cent\n",
    "            if get_sb:\n",
    "                features_tmp = spec_bw\n",
    "            if get_sr:\n",
    "                features_tmp = rolloff\n",
    "            \n",
    "\n",
    "            features_local.append(features_tmp)\n",
    "\n",
    "        # If features_local is empty, skip the file\n",
    "        if features_local == []:\n",
    "            print(f\"No features extracted for {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Stack the MFCC features into a single tensor\n",
    "        features_local = torch.stack(features_local, dim=0)\n",
    "\n",
    "        # Attach the label in the last column\n",
    "        features_local = torch.cat(\n",
    "            (features_local, torch.ones(features_local.shape[0], 1) * label), dim=1\n",
    "        )\n",
    "\n",
    "        # Attach the filename index in the last column\n",
    "        features_local = torch.cat(\n",
    "            (\n",
    "                features_local,\n",
    "                torch.full((features_local.shape[0], 1), filenames.index(file)),\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        features.append(features_local)\n",
    "\n",
    "    print(\"Finished processing all files.\\n\")\n",
    "    return features\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def extract_rms(audio: torch.Tensor, num_values: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract RMS features from an audio file.\n",
    "\n",
    "    Args:\n",
    "    - audio (torch.Tensor): The audio file.\n",
    "    - num_values (int): The number of RMS values to extract.\n",
    "\n",
    "    Returns:\n",
    "    - rms (torch.Tensor): The RMS features of the audio file.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_samples = audio.shape[1]\n",
    "    hop_length = num_samples // num_values\n",
    "\n",
    "    \n",
    "    rms = librosa.feature.rms(y=audio.numpy(), frame_length=hop_length*2, hop_length=hop_length, center=True)\n",
    "    rms = torch.tensor(rms)\n",
    "    return rms.reshape(-1)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def extract_zero_crossing_rate(audio: torch.Tensor, num_values: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract Zero Crossing Rate features from an audio file.\n",
    "\n",
    "    Args:\n",
    "    - audio (torch.Tensor): The audio file.\n",
    "    - num_values (int): The number of Zero Crossing Rate values to extract.\n",
    "\n",
    "    Returns:\n",
    "    - zcr (torch.Tensor): The Zero Crossing Rate features of the audio file.\n",
    "    \"\"\"\n",
    "    num_samples = audio.shape[1]\n",
    "    hop_length = num_samples // num_values\n",
    "    \n",
    "    zcr = librosa.feature.zero_crossing_rate(y=audio.numpy(), frame_length=hop_length*2, hop_length=hop_length)\n",
    "    zcr = torch.tensor(zcr)\n",
    "    return zcr.reshape(-1)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def extract_spectral_centroid(audio: torch.Tensor, sample_rate: int, num_values: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract Spectral Centroid features from an audio file.\n",
    "\n",
    "    Args:\n",
    "    - audio (torch.Tensor): The audio file.\n",
    "    - sample_rate (int): The sample rate of the audio file.\n",
    "    - num_values (int): The number of Spectral Centroid values to extract.\n",
    "\n",
    "    Returns:\n",
    "    - spec_cent (torch.Tensor): The Spectral Centroid features of the audio file.\n",
    "    \"\"\"\n",
    "    num_samples = audio.shape[1]\n",
    "    hop_length = num_samples // num_values\n",
    "    \n",
    "    sb = librosa.feature.spectral_centroid(y=audio.numpy(), n_fft=hop_length*2, hop_length=hop_length, sr=sample_rate)\n",
    "    sb = torch.tensor(sb)\n",
    "    return sb.reshape(-1)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def extract_spectral_bandwidth(audio: torch.Tensor, sample_rate: int, num_values:int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract Spectral Bandwidth features from an audio file.\n",
    "\n",
    "    Args:\n",
    "    - audio (torch.Tensor): The audio file.\n",
    "    - sample_rate (int): The sample rate of the audio file.\n",
    "    - num_values (int): The number of Spectral Bandwidth values to extract.\n",
    "\n",
    "    Returns:\n",
    "    - spec_bw (torch.Tensor): The Spectral Bandwidth features of the audio file.\n",
    "    \"\"\"\n",
    "    num_samples = audio.shape[1]\n",
    "    hop_length = num_samples // num_values\n",
    "    \n",
    "    sc = librosa.feature.spectral_bandwidth(y=audio.numpy(), n_fft=hop_length*2, hop_length=hop_length, sr=sample_rate)\n",
    "    sc = torch.tensor(sc)\n",
    "    return sc.reshape(-1)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def extract_spectral_rolloff(audio: torch.Tensor, sample_rate: int, num_values:int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract Spectral Rolloff features from an audio file.\n",
    "\n",
    "    Args:\n",
    "    - audio (torch.Tensor): The audio file.\n",
    "    - sample_rate (int): The sample rate of the audio file.\n",
    "    - num_values (int): The number of Spectral Rolloff values to extract.\n",
    "\n",
    "    Returns:\n",
    "    - rolloff (torch.Tensor): The Spectral Rolloff features of the audio file.\n",
    "    \"\"\"\n",
    "    num_samples = audio.shape[1]\n",
    "    hop_length = num_samples // num_values\n",
    "    \n",
    "    sr = librosa.feature.spectral_rolloff(y=audio.numpy(), n_fft=hop_length*2, hop_length=hop_length, sr=sample_rate)\n",
    "    sr = torch.tensor(sr)\n",
    "    return sr.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts_4000/\n",
      "No files found in ../dataset/artifacts_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c1f1bbf4d7d46438afd2a8a3b7c7567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for noisy_3USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for pitch_1USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (329, 32)\n",
      "Extracting features from ../dataset/murmurs_4000/\n",
      "No files found in ../dataset/murmurs_4000/. Exiting...\n",
      "Extracting features from ../dataset/normals_4000/\n",
      "No files found in ../dataset/normals_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7217b2ccc370426e9d35de22543597b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (91, 32)\n",
      "Features extracted and saved\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- MFCC -------------------------\n",
    "#n_mfcc_list = [30, 60, 90, 120]\n",
    "n_mfcc_list = [30]\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"mfcc\"  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for n_mfcc in n_mfcc_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_mfcc}{type_}_USERAUGMENTED\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_mfcc=n_mfcc,\n",
    "                get_mfcc=True,\n",
    "                get_chroma=False,\n",
    "                get_cqt=False,\n",
    "            )\n",
    "            if features == 200: #CODE RETURNED WHEN NO FILES ARE FOUND\n",
    "                continue\n",
    "            \n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts_4000/\n",
      "No files found in ../dataset/artifacts_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59d210a59b694e46b7f6d77018e9577c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for noisy_3USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for pitch_1USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (329, 14)\n",
      "Extracting features from ../dataset/murmurs_4000/\n",
      "No files found in ../dataset/murmurs_4000/. Exiting...\n",
      "Extracting features from ../dataset/normals_4000/\n",
      "No files found in ../dataset/normals_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71f6c2bd653644a497d3af562edb0116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (91, 14)\n",
      "Features extracted and saved\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- CHROMA -------------------------\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "n_features = 12\n",
    "type_ = \"chroma\"  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for n_mfcc in n_mfcc_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_features}{type_}_USERAUGMENTED\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_mfcc=n_mfcc,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=True,\n",
    "                get_cqt=False,\n",
    "            )\n",
    "            \n",
    "            if features == 200:\n",
    "                continue\n",
    "\n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts_4000/\n",
      "No files found in ../dataset/artifacts_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d31b51c8204a649c04618a2b4f3e88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=128 is too large for input signal of length=125\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for noisy_3USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for pitch_1USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (329, 72)\n",
      "Extracting features from ../dataset/murmurs_4000/\n",
      "No files found in ../dataset/murmurs_4000/. Exiting...\n",
      "Extracting features from ../dataset/normals_4000/\n",
      "No files found in ../dataset/normals_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d886b59a1194b59a0465f4315ef173a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (91, 72)\n",
      "Features extracted and saved\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- CQT -------------------------\n",
    "# n_cqt_list = [\n",
    "#     20,\n",
    "#     30,\n",
    "#     40,\n",
    "#     60,\n",
    "#     70,\n",
    "# ]\n",
    "n_cqt_list = [70]\n",
    "\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"cqt\"  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for n_cqt in n_cqt_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_cqt}{type_}_USERAUGMENTED\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_cqt=n_cqt,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=False,\n",
    "                get_cqt=True,\n",
    "            )\n",
    "            \n",
    "            if features == 200:\n",
    "                continue\n",
    "\n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts_4000/\n",
      "No files found in ../dataset/artifacts_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bc23833051412dab9f43596253878e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for noisy_3USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for pitch_1USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (329, 43)\n",
      "Extracting features from ../dataset/murmurs_4000/\n",
      "No files found in ../dataset/murmurs_4000/. Exiting...\n",
      "Extracting features from ../dataset/normals_4000/\n",
      "No files found in ../dataset/normals_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d68cf73ae8e94869a3995de6d9b12c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (91, 43)\n",
      "Features extracted and saved\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- RMS -------------------------\n",
    "# n_rms_list = [\n",
    "#     20,\n",
    "#     40,\n",
    "#     60,\n",
    "# ]\n",
    "\n",
    "n_rms_list = [40]\n",
    "\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"rms\"  # mfcc, mel_spec, spec, cqt, rms\n",
    "\n",
    "for n_rms in n_rms_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_rms+1}{type_}_USERAUGMENTED\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_rms=n_rms,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=False,\n",
    "                get_cqt=False,\n",
    "                get_rms=True,\n",
    "            )\n",
    "            if features == 200:\n",
    "                continue\n",
    "\n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts_4000/\n",
      "No files found in ../dataset/artifacts_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f75ffa148eba44c4aa53495508b572c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for noisy_3USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for pitch_1USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (329, 43)\n",
      "Extracting features from ../dataset/murmurs_4000/\n",
      "No files found in ../dataset/murmurs_4000/. Exiting...\n",
      "Extracting features from ../dataset/normals_4000/\n",
      "No files found in ../dataset/normals_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9efe063f2834f119d2cd30bb5b9fcee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (91, 43)\n",
      "Features extracted and saved\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- ZCR -------------------------\n",
    "# n_zcr_list = [\n",
    "#     20,\n",
    "#     40,\n",
    "#     60,\n",
    "# ]\n",
    "n_zcr_list = [40]\n",
    "\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"zcr\"  # mfcc, mel_spec, spec, cqt, rms\n",
    "\n",
    "for n_zcr in n_zcr_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_zcr+1}{type_}_USERAUGMENTED\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_zcr=n_zcr,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=False,\n",
    "                get_cqt=False,\n",
    "                get_rms=False,\n",
    "                get_zcr=True,\n",
    "            )\n",
    "            if features == 200:\n",
    "                continue\n",
    "            \n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts_4000/\n",
      "No files found in ../dataset/artifacts_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b84ecf4cb6954512868971f1d301fd02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for noisy_3USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for pitch_1USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (329, 43)\n",
      "Extracting features from ../dataset/murmurs_4000/\n",
      "No files found in ../dataset/murmurs_4000/. Exiting...\n",
      "Extracting features from ../dataset/normals_4000/\n",
      "No files found in ../dataset/normals_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244ad566775c4df299becf0b8fbe6f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (91, 43)\n",
      "Features extracted and saved\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- SPECTRAL CENTROID -------------------------\n",
    "# n_sc_list = [\n",
    "#     20,\n",
    "#     40,\n",
    "#     60,\n",
    "# ]\n",
    "n_sc_list = [40]\n",
    "\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"sc\"  # mfcc, mel_spec, spec, cqt, rms\n",
    "\n",
    "for n_sc in n_sc_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_sc+1}{type_}_USERAUGMENTED\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_sc=n_sc,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=False,\n",
    "                get_cqt=False,\n",
    "                get_rms=False,\n",
    "                get_zcr=False,\n",
    "                get_sc=True,\n",
    "            )\n",
    "            if features == 200:\n",
    "                continue\n",
    "            \n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts_4000/\n",
      "No files found in ../dataset/artifacts_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65792e980f5a481e93758208750f8cca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for noisy_3USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for pitch_1USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (329, 63)\n",
      "Extracting features from ../dataset/murmurs_4000/\n",
      "No files found in ../dataset/murmurs_4000/. Exiting...\n",
      "Extracting features from ../dataset/normals_4000/\n",
      "No files found in ../dataset/normals_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f20855489324f1b97b22954c018f1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (91, 63)\n",
      "Features extracted and saved\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- SPECTRAL BANDWIDTH -------------------------\n",
    "# n_sb_list = [\n",
    "#     20,\n",
    "#     40,\n",
    "#     60,\n",
    "# ]\n",
    "\n",
    "n_sb_list = [60]\n",
    "\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"sb\"  # mfcc, mel_spec, spec, cqt, rms\n",
    "\n",
    "for n_sb in n_sb_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_sb+1}{type_}_USERAUGMENTED\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_sb=n_sb,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=False,\n",
    "                get_cqt=False,\n",
    "                get_rms=False,\n",
    "                get_zcr=False,\n",
    "                get_sc=False,\n",
    "                get_sb = True\n",
    "            )\n",
    "            if features == 200:\n",
    "                continue\n",
    "            \n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts_4000/\n",
      "No files found in ../dataset/artifacts_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35093c55bc0e472b906695d8779b425d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for noisy_3USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for pitch_1USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (329, 43)\n",
      "Extracting features from ../dataset/murmurs_4000/\n",
      "No files found in ../dataset/murmurs_4000/. Exiting...\n",
      "Extracting features from ../dataset/normals_4000/\n",
      "No files found in ../dataset/normals_4000/. Exiting...\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34d1b26963e49229bda32aeadf7b544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (91, 43)\n",
      "Features extracted and saved\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- SPECTRAL ROLLOFF -------------------------\n",
    "# n_sr_list = [\n",
    "#     20,\n",
    "#     40,\n",
    "#     60,\n",
    "# ]\n",
    "\n",
    "n_sr_list = [40]\n",
    "\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"sr\"  # mfcc, mel_spec, spec, cqt, rms\n",
    "\n",
    "for n_sr in n_sr_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_sr+1}{type_}_USERAUGMENTED\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_sr=n_sr,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=False,\n",
    "                get_cqt=False,\n",
    "                get_rms=False,\n",
    "                get_zcr=False,\n",
    "                get_sc=False,\n",
    "                get_sb = False,\n",
    "                get_sr=True,\n",
    "            )\n",
    "            if features == 200:\n",
    "                continue\n",
    "            \n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Features Extraction\n",
    "\n",
    "- **MFCC (Mel-Frequency Cepstral Coefficients)**: n_mfcc chosen by the user\n",
    "- **Chroma STFT**: 12 coefficients\n",
    "- **CQT (Constant-Q Transform)**: n_cqt chosen by the user\n",
    "- **RMS (Root Mean Square) Energy**: 1 coefficient\n",
    "- **Spectral Centroid**: 1 coefficient\n",
    "- **Spectral Bandwidth**: 1 coefficient\n",
    "- **Spectral Roll-off**: 1 coefficient\n",
    "- **Zero Crossing Rate**: 1 coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FEATURES EXTRACTION\n",
    "# names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "# features_dict = {}\n",
    "# interval = 1\n",
    "# n_mfcc = 30  # 30, 120\n",
    "# n_cqt = 70  # 30, 70\n",
    "\n",
    "# # melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "# # Save the features to a file\n",
    "# storing_name = f\"full_data_{interval}s_{sr}hz_{n_mfcc}mfcc_{n_cqt}cqt_12chroma\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "\n",
    "# if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "#     print(\"The features have already been extracted\")\n",
    "\n",
    "# else:\n",
    "#     for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "#         print(f\"Extracting features from {PATH_}\")\n",
    "#         features = utils.extract_features(\n",
    "#             PATH_, label=i, frame_length=interval, n_mfcc=n_mfcc, n_cqt=n_cqt\n",
    "#         )\n",
    "\n",
    "#         # Stack the features into a single tensor\n",
    "#         features = torch.cat(features, dim=0).numpy()\n",
    "#         print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "#         X = features[:, :-2]\n",
    "#         y = features[:, -2]\n",
    "#         filename = features[:, -1]\n",
    "\n",
    "#         local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "#         features_dict[names[i]] = local_dict\n",
    "\n",
    "#     # Save the features to a file\n",
    "#     np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "#     print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the features and check the shape\n",
    "# features_dict = np.load(\n",
    "#     FEATURES_RAW_DIR + storing_name + \".npy\", allow_pickle=True\n",
    "# ).item()\n",
    "# for key in features_dict.keys():\n",
    "#     print(f'The shape of the {key} features tensor is: {features_dict[key][\"X\"].shape}')\n",
    "#     print(f'The shape of the {key} labels tensor is: {features_dict[key][\"y\"].shape}')\n",
    "#     print(\n",
    "#         f'The shape of the {key} filenames tensor is: {features_dict[key][\"filename\"].shape}'\n",
    "#     )\n",
    "#     print(\"-----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = 0\n",
    "# for key in features_dict.keys():\n",
    "#     s += features_dict[key][\"X\"].shape[0]\n",
    "# s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
