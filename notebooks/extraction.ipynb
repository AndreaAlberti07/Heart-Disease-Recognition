{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Notebook\n",
    "---\n",
    "\n",
    "This notebook is used to extract features from the data. The audio is divided into windows of 1 second. The features extracted from each audio window are:\n",
    "- MFCC (Mel-Frequency Cepstral Coefficients): 20 coefficients\n",
    "- Chroma STFT: 1 coefficient\n",
    "- RMS (Root Mean Square) Energy: 1 coefficient\n",
    "- Spectral Centroid: 1 coefficient\n",
    "- Spectral Bandwidth: 1 coefficient\n",
    "- Spectral Roll-off: 1 coefficient\n",
    "- Zero Crossing Rate: 1 coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the functions\n",
    "from utils import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n",
       "\n",
       "# -------- tqdm DARK THEME --------\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>\n",
    "\n",
    "# -------- tqdm DARK THEME --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the paths to data\n",
    "BASE_DIR = '../dataset/'\n",
    "ARTIFACTS_DIR = BASE_DIR + 'artifacts/'\n",
    "EXTRAHLS_DIR = BASE_DIR + 'extrahls/'\n",
    "MURMURS_DIR = BASE_DIR + 'murmurs/'\n",
    "NORMALS_DIR = BASE_DIR + 'normals/'\n",
    "EXTRASTOLES_DIR = BASE_DIR + 'extrastoles/'\n",
    "\n",
    "# paths to save the features\n",
    "FEATURES_DIR = '../features/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ff22c13a464505ae6422db14cb812a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_17.wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_16.wav...\n",
      "Converting stereo audio to mono for artifact_2023_14.wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_15.wav...\n",
      "Converting stereo audio to mono for artifact_2023_39.wav...\n",
      "Converting stereo audio to mono for artifact_2023_11.wav...\n",
      "Converting stereo audio to mono for artifact_2023_38.wav...\n",
      "Converting stereo audio to mono for artifact_2023_12.wav...\n",
      "Converting stereo audio to mono for artifact_2023_13.wav...\n",
      "Converting stereo audio to mono for artifact_2023_49.wav...\n",
      "Converting stereo audio to mono for artifact_2023_41.wav...\n",
      "Converting stereo audio to mono for artifact_2023_40.wav...\n",
      "Converting stereo audio to mono for artifact_2023_42.wav...\n",
      "Converting stereo audio to mono for artifact_2023_43.wav...\n",
      "Converting stereo audio to mono for artifact_2023_47.wav...\n",
      "Converting stereo audio to mono for artifact_2023_46.wav...\n",
      "Converting stereo audio to mono for artifact_2023_50.wav...\n",
      "Converting stereo audio to mono for artifact_2023_44.wav...\n",
      "Converting stereo audio to mono for artifact_2023_45.wav...\n",
      "Converting stereo audio to mono for artifact_2023_51.wav...\n",
      "Converting stereo audio to mono for artifact_2023_36.wav...\n",
      "Converting stereo audio to mono for artifact_2023_22.wav...\n",
      "Converting stereo audio to mono for artifact_2023_4.wav...\n",
      "Converting stereo audio to mono for artifact_2023_5.wav...\n",
      "Converting stereo audio to mono for artifact_2023_23.wav...\n",
      "Converting stereo audio to mono for artifact_2023_37.wav...\n",
      "Converting stereo audio to mono for artifact_2023_21.wav...\n",
      "Converting stereo audio to mono for artifact_2023_35.wav...\n",
      "Converting stereo audio to mono for artifact_2023_7.wav...\n",
      "Converting stereo audio to mono for artifact_2023_6.wav...\n",
      "Converting stereo audio to mono for artifact_2023_34.wav...\n",
      "Converting stereo audio to mono for artifact_2023_20.wav...\n",
      "Converting stereo audio to mono for artifact_2023_18.wav...\n",
      "Converting stereo audio to mono for artifact_2023_24.wav...\n",
      "Converting stereo audio to mono for artifact_2023_2.wav...\n",
      "Converting stereo audio to mono for artifact_2023_25.wav...\n",
      "Converting stereo audio to mono for artifact_2023_19.wav...\n",
      "Converting stereo audio to mono for artifact_2023_33.wav...\n",
      "Converting stereo audio to mono for artifact_2023_1.wav...\n",
      "Converting stereo audio to mono for artifact_2023_0.wav...\n",
      "Converting stereo audio to mono for artifact_2023_26.wav...\n",
      "Converting stereo audio to mono for artifact_2023_32.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/artifacts/ features tensor is: torch.Size([2000, 28])\n",
      "Saving features...\n",
      "Extracting features from ../dataset/extrahls/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3235a9c82587419eb4745148df16fd71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for extrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls/ features tensor is: torch.Size([124, 28])\n",
      "Saving features...\n",
      "Extracting features from ../dataset/murmurs/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce3a74a7f8e4dc9a2587c83c0d29beb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for murmur__201104021355.wav. Skipping...\n",
      "Converting stereo audio to mono for abnormal_s4_2023_2.wav...\n",
      "No features extracted for murmur__171_1307971016233_E.wav. Skipping...\n",
      "Converting stereo audio to mono for atrial_septal_defect_2023_6.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_1.wav...\n",
      "Converting stereo audio to mono for mitral_stenosis_2023_9.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_0.wav...\n",
      "Converting stereo audio to mono for holosystolic_murmur_2023_7.wav...\n",
      "Converting stereo audio to mono for aortic_stenosis_2023_4.wav...\n",
      "Converting stereo audio to mono for mitral_valve_prolapse_2023_10.wav...\n",
      "Converting stereo audio to mono for innocent_murmur_2023_8.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/murmurs/ features tensor is: torch.Size([1149, 28])\n",
      "Saving features...\n",
      "Extracting features from ../dataset/normals/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15d2537ce6aa433198d7b3ff251449cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for normal__296_1311682952647_A1.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_3.wav...\n",
      "Converting stereo audio to mono for normal_2023_2.wav...\n",
      "Converting stereo audio to mono for normal_2023_0.wav...\n",
      "Converting stereo audio to mono for normal_2023_1.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/normals/ features tensor is: torch.Size([2161, 28])\n",
      "Saving features...\n",
      "Extracting features from ../dataset/extrastoles/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccd52a3843cf4fea91c849d9356bf4e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles/ features tensor is: torch.Size([247, 28])\n",
      "Saving features...\n"
     ]
    }
   ],
   "source": [
    "# FEATURES EXTRACTION\n",
    "paths = [ARTIFACTS_DIR, EXTRAHLS_DIR, MURMURS_DIR, NORMALS_DIR, EXTRASTOLES_DIR]\n",
    "names = ['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles']\n",
    "window_length = 1\n",
    "sample_rate = 44100\n",
    "n_mfcc = 20\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for i, path in enumerate(paths):\n",
    "     \n",
    "     # Save the features to a file\n",
    "     name = f'{names[i]}_{window_length}.npz'\n",
    "     \n",
    "     if os.path.exists(FEATURES_DIR + name):\n",
    "          print('The features have already been extracted')\n",
    "     else:\n",
    "          print(f'Extracting features from {path}')\n",
    "          features = extract_features(path, label = i, frame_length = window_length, sample_rate=sample_rate, n_mfcc=n_mfcc)\n",
    "          \n",
    "          # Stack the features into a single tensor\n",
    "          features = torch.cat(features, dim=0)\n",
    "          print(f'The shape of the {path} features tensor is: {features.shape}')\n",
    "          \n",
    "          # if returns None continue\n",
    "          if save_features(features, FEATURES_DIR, name) == None:\n",
    "               continue\n",
    "    \n",
    "     print('Features extracted and saved')\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show the features statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifacts features\n",
      "Max: 21160.455953663793, Min: -1131.369384765625, Mean: 483.97492510688136, Std: 1852.854843619321      -       Shape: (2000, 26)\n",
      "\n",
      "extrahls features\n",
      "Max: 18953.178879310344, Min: -674.0330810546875, Mean: 753.7483613723052, Std: 2587.231366594324       -       Shape: (124, 26)\n",
      "\n",
      "murmur features\n",
      "Max: 13025.607825969828, Min: -574.7505493164062, Mean: 105.72155305406422, Std: 538.6539669046897      -       Shape: (1149, 26)\n",
      "\n",
      "normal features\n",
      "Max: 16976.08432112069, Min: -654.86279296875, Mean: 111.12140859068722, Std: 738.1790744503893         -       Shape: (2161, 26)\n",
      "\n",
      "extrastoles features\n",
      "Max: 1057.6171875, Min: -309.2425537109375, Mean: 37.46883951805036, Std: 130.15941934366995            -       Shape: (247, 26)\n"
     ]
    }
   ],
   "source": [
    "artifacts_features = np.load(FEATURES_DIR + 'artifacts_1.npz')['X']\n",
    "max = artifacts_features.max()\n",
    "min = artifacts_features.min()\n",
    "mean = artifacts_features.mean()\n",
    "std = artifacts_features.std()\n",
    "print('artifacts features')\n",
    "print(f'Max: {max}, Min: {min}, Mean: {mean}, Std: {std}      -       Shape: {artifacts_features.shape}\\n')\n",
    "\n",
    "extrahls_features = np.load(FEATURES_DIR + 'extrahls_1.npz')['X']\n",
    "max = extrahls_features.max()\n",
    "min = extrahls_features.min()\n",
    "mean = extrahls_features.mean()\n",
    "std = extrahls_features.std()\n",
    "print('extrahls features')\n",
    "print(f'Max: {max}, Min: {min}, Mean: {mean}, Std: {std}       -       Shape: {extrahls_features.shape}\\n')\n",
    "\n",
    "murmur_features = np.load(FEATURES_DIR + 'murmurs_1.npz')['X']\n",
    "max = murmur_features.max()\n",
    "min = murmur_features.min()\n",
    "mean = murmur_features.mean()\n",
    "std = murmur_features.std()\n",
    "print('murmur features')\n",
    "print(f'Max: {max}, Min: {min}, Mean: {mean}, Std: {std}      -       Shape: {murmur_features.shape}\\n')\n",
    "\n",
    "normal_features = np.load(FEATURES_DIR + 'normals_1.npz')['X']\n",
    "max = normal_features.max()\n",
    "min = normal_features.min()\n",
    "mean = normal_features.mean()\n",
    "std = normal_features.std()\n",
    "print('normal features')\n",
    "print(f'Max: {max}, Min: {min}, Mean: {mean}, Std: {std}         -       Shape: {normal_features.shape}\\n')\n",
    "\n",
    "extrastoles_features = np.load(FEATURES_DIR + 'extrastoles_1.npz')['X']\n",
    "max = extrastoles_features.max()\n",
    "min = extrastoles_features.min()\n",
    "mean = extrastoles_features.mean()\n",
    "std = extrastoles_features.std()\n",
    "print('extrastoles features')\n",
    "print(f'Max: {max}, Min: {min}, Mean: {mean}, Std: {std}            -       Shape: {extrastoles_features.shape}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
