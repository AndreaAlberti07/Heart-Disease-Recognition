{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Notebook\n",
    "---\n",
    "\n",
    "This notebook is used to extract features from the data. The audio is divided into windows of 1 second. The features extracted from each audio window are:\n",
    "- **MFCC (Mel-Frequency Cepstral Coefficients)**: n_mfcc chosen by the user\n",
    "- **Chroma STFT**: 12 coefficients\n",
    "- **CQT (Constant-Q Transform)**: n_cqt chosen by the user\n",
    "- **RMS (Root Mean Square) Energy**: 1 coefficient\n",
    "- **Spectral Centroid**: 1 coefficient\n",
    "- **Spectral Bandwidth**: 1 coefficient\n",
    "- **Spectral Roll-off**: 1 coefficient\n",
    "- **Zero Crossing Rate**: 1 coefficient\n",
    "\n",
    "#### Sections:\n",
    "- [Feature Extraction](#Feature-Extraction)\n",
    "  - [Specific Features Extraction](#Specific-Features-Extraction)\n",
    "  - [All Features Extraction](#All-Features-Extraction)\n",
    "\n",
    "  \n",
    "#### Findings:\n",
    "- We have highly unbalanced classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the functions\n",
    "import utils as utils\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import importlib\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "# import the utils module\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>\n",
    "\n",
    "# -------- tqdm DARK THEME --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "sr = 'mix'\n",
    "#sr = 4000\n",
    "\n",
    "# set the paths to data\n",
    "BASE_DIR = '../dataset/'\n",
    "ARTIFACTS_DIR = BASE_DIR + f'artifacts/'\n",
    "EXTRAHLS_DIR = BASE_DIR + f'extrahls/'\n",
    "MURMURS_DIR = BASE_DIR + f'murmurs/'\n",
    "NORMALS_DIR = BASE_DIR + f'normals/'\n",
    "EXTRASTOLES_DIR = BASE_DIR + f'extrastoles/'\n",
    "\n",
    "# paths to save the features\n",
    "FEATURES_RAW_DIR = '../features/raw/'\n",
    "#FEATURES_RAW_DIR = \"../features/balanced/priori/\"\n",
    "\n",
    "PATHS = [ARTIFACTS_DIR, EXTRAHLS_DIR, MURMURS_DIR, NORMALS_DIR, EXTRASTOLES_DIR]\n",
    "\n",
    "# REMOVE THE AUGEMENTED SAMPLES WHEN EXTRACTING BASE RAW FEATURES\n",
    "# for path in PATHS:\n",
    "#      utils.remove_generated_samples(path, 'USERAUGMENTED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Features Extraction\n",
    "- **MFCC (Mel-Frequency Cepstral Coefficients)**: n_mfcc chosen by the user\n",
    "- **Chroma STFT**: 12 coefficients\n",
    "- **CQT (Constant-Q Transform)**: n_cqt chosen by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(\n",
    "    dir_path: str,\n",
    "    label: str,\n",
    "    frame_length: float,\n",
    "    sample_rate: int = 44100,\n",
    "    n_mfcc: int = 13,\n",
    "    melkwargs: dict = {},\n",
    "    n_cqt: int = 84,\n",
    "    get_mfcc: bool = True,\n",
    "    get_chroma: bool = True,\n",
    "    get_cqt: bool = True,\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Extracts audio features (MFCC, chroma, RMS, spectral centroid, spectral bandwidth, spectral rolloff, zero-crossing rate)\n",
    "    from audio files in the specified directory.\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): The path to the directory containing audio files.\n",
    "        label (str): The label associated with the extracted features.\n",
    "        frame_length: The frame length for feature extraction.\n",
    "        sample_rate (int, optional): The sample rate of the audio files. Defaults to 44100 Hz.\n",
    "        n_mfcc (int, optional): The number of Mel-frequency cepstral coefficients (MFCCs) to extract. Defaults to 13.\n",
    "        melkwargs (dict, optional): Additional arguments for Mel spectrogram computation.\n",
    "        n_cqt (int, optional): The number of constant-Q transform (CQT) bins to extract. Defaults to 84.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list containing tensors of extracted features for each audio file.\n",
    "    \"\"\"\n",
    "    filenames = os.listdir(dir_path)\n",
    "    filenames = [file for file in filenames if not file.startswith(\".\")]\n",
    "    frame_length = int(1 / frame_length)\n",
    "\n",
    "    features = []  # List to store the features for all files\n",
    "\n",
    "    for file in tqdm(filenames, desc=f\"Extraction in progress\"):\n",
    "        audio, orig_sample_rate = torchaudio.load(os.path.join(dir_path, file))\n",
    "        orig_sample_rate_tmp = int(orig_sample_rate / frame_length)\n",
    "        audio_length = int(max(audio[0].shape) / (orig_sample_rate_tmp))\n",
    "\n",
    "        sample_rate = orig_sample_rate\n",
    "\n",
    "        # Reduce the audio from stereo to mono if needed\n",
    "        if audio.shape[0] > 1:\n",
    "            print(f\"Converting stereo audio to mono for {file}...\")\n",
    "            audio = torch.mean(audio, dim=0).reshape(1, -1)\n",
    "\n",
    "        features_local = []  # List to store the MFCC features for each file\n",
    "\n",
    "        for i in range(audio_length):\n",
    "            # Lazy load the audio, one sec at a time, to avoid memory issues\n",
    "            audio_mono = utils.slicing(\n",
    "                audio,\n",
    "                offset=int(sample_rate / frame_length * i),\n",
    "                num_frames=int(sample_rate / frame_length * (i + 1)),\n",
    "            )\n",
    "\n",
    "            # Get the MFCC features\n",
    "            if get_mfcc:\n",
    "                mfcc_features_tmp = utils.extract_mfcc(audio_mono, sample_rate, n_mfcc, melkwargs)\n",
    "            if get_chroma:\n",
    "                chroma_stft = utils.extract_chroma_stft(audio_mono, sample_rate)\n",
    "            if get_cqt:\n",
    "                cqt = utils.extract_cqt(audio_mono, sample_rate=sample_rate, n_cqt=n_cqt)\n",
    "\n",
    "          #   rms = extract_rms(audio_mono)\n",
    "          #   spec_cent = extract_spectral_centroid(audio_mono, sample_rate)\n",
    "          #   spec_bw = extract_spectral_bandwidth(audio_mono, sample_rate)\n",
    "          #   rolloff = extract_spectral_rolloff(audio_mono, sample_rate)\n",
    "          #   zcr = extract_zero_crossing_rate(audio_mono)\n",
    "\n",
    "            \n",
    "            # Concatenate the features\n",
    "            if get_mfcc:\n",
    "                features_tmp = mfcc_features_tmp\n",
    "            if get_chroma:\n",
    "                features_tmp = chroma_stft\n",
    "            if get_cqt:\n",
    "                features_tmp = cqt\n",
    "            \n",
    "            if get_mfcc and get_chroma:\n",
    "                features_tmp = torch.cat(\n",
    "                    (mfcc_features_tmp, chroma_stft),\n",
    "                    dim=0,\n",
    "                )\n",
    "            if get_mfcc and get_cqt:\n",
    "                features_tmp = torch.cat(\n",
    "                    (mfcc_features_tmp, cqt),\n",
    "                    dim=0,\n",
    "                )\n",
    "            if get_chroma and get_cqt:\n",
    "                features_tmp = torch.cat(\n",
    "                    (chroma_stft, cqt),\n",
    "                    dim=0,\n",
    "                )\n",
    "            if get_mfcc and get_chroma and get_cqt:\n",
    "                features_tmp = torch.cat(\n",
    "                    (mfcc_features_tmp, chroma_stft, cqt),\n",
    "                    dim=0,\n",
    "                )\n",
    "            if not get_mfcc and not get_chroma and not get_cqt:\n",
    "                features_tmp = torch.tensor([])\n",
    "\n",
    "            features_local.append(features_tmp)\n",
    "\n",
    "\n",
    "        # If features_local is empty, skip the file\n",
    "        if features_local == []:\n",
    "            print(f\"No features extracted for {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Stack the MFCC features into a single tensor\n",
    "        features_local = torch.stack(features_local, dim=0)\n",
    "\n",
    "        # Attach the label in the last column\n",
    "        features_local = torch.cat(\n",
    "            (features_local, torch.ones(features_local.shape[0], 1) * label), dim=1\n",
    "        )\n",
    "\n",
    "        # Attach the filename index in the last column\n",
    "        features_local = torch.cat(\n",
    "            (\n",
    "                features_local,\n",
    "                torch.full((features_local.shape[0], 1), filenames.index(file)),\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        features.append(features_local)\n",
    "\n",
    "    print(\"Finished processing all files.\\n\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- MFCC -------------------------\n",
    "n_mfcc_list = [30, 120]\n",
    "names = ['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles']\n",
    "features_dict = {}\n",
    "interval = 1\n",
    "type_ = 'mfcc'  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for n_mfcc in n_mfcc_list:\n",
    "\t# Save the features to a file\n",
    "\tstoring_name = f'full_data_{interval}s_{sr}hz_{n_mfcc}{type_}'  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "\tif os.path.exists(FEATURES_RAW_DIR + storing_name + '.npy'):\n",
    "\t\tprint('The features have already been extracted')\n",
    "\t\t\n",
    "\telse:\n",
    "\t\tfor i, PATH_ in enumerate(PATHS):\n",
    "\t\t\t\n",
    "\t\t\tprint(f'Extracting features from {PATH_}')\n",
    "\t\t\tfeatures = extract_features(PATH_, label = i, frame_length = interval, n_mfcc=n_mfcc, get_mfcc=True, get_chroma=False, get_cqt=False)\n",
    "\t\t\t\n",
    "\t\t\t# Stack the features into a single tensor\n",
    "\t\t\tfeatures = torch.cat(features, dim=0).numpy()\n",
    "\t\t\tprint(f'The shape of the {PATH_} features tensor is: {features.shape}')\n",
    "\t\t\t\n",
    "\t\t\tX = features[:,:-2]\n",
    "\t\t\ty = features[:,-2]\n",
    "\t\t\tfilename = features[:,-1]\n",
    "\t\t\t\n",
    "\t\t\tlocal_dict = {'X': X, 'y': y, 'filename': filename}\n",
    "\t\t\t\n",
    "\t\t\tfeatures_dict[names[i]] = local_dict\n",
    "\t\t\t\t\n",
    "\t\t# Save the features to a file\n",
    "\t\tnp.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\t\t\t\t\n",
    "\t\tprint('Features extracted and saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- CHROMA -------------------------\n",
    "names = ['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles']\n",
    "features_dict = {}\n",
    "interval = 1\n",
    "n_features = 12\n",
    "type_ = 'chroma'  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for n_mfcc in n_mfcc_list:\n",
    "\t# Save the features to a file\n",
    "\tstoring_name = f'full_data_{interval}s_{sr}hz_{n_features}{type_}'  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "\n",
    "\tif os.path.exists(FEATURES_RAW_DIR + storing_name + '.npy'):\n",
    "\t\tprint('The features have already been extracted')\n",
    "\t\t\n",
    "\telse:\n",
    "\t\tfor i, PATH_ in enumerate(PATHS):\n",
    "\t\t\t\n",
    "\t\t\tprint(f'Extracting features from {PATH_}')\n",
    "\t\t\tfeatures = extract_features(PATH_, label = i, frame_length = interval, n_mfcc=n_mfcc, get_mfcc=False, get_chroma=True, get_cqt=False)\n",
    "\t\t\t\n",
    "\t\t\t# Stack the features into a single tensor\n",
    "\t\t\tfeatures = torch.cat(features, dim=0).numpy()\n",
    "\t\t\tprint(f'The shape of the {PATH_} features tensor is: {features.shape}')\n",
    "\t\t\t\n",
    "\t\t\tX = features[:,:-2]\n",
    "\t\t\ty = features[:,-2]\n",
    "\t\t\tfilename = features[:,-1]\n",
    "\t\t\t\n",
    "\t\t\tlocal_dict = {'X': X, 'y': y, 'filename': filename}\n",
    "\t\t\t\n",
    "\t\t\tfeatures_dict[names[i]] = local_dict\n",
    "\t\t\t\t\n",
    "\t\t# Save the features to a file\n",
    "\t\tnp.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\t\t\t\t\n",
    "\t\tprint('Features extracted and saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- CQT -------------------------\n",
    "n_cqt_list = [30, 70]\n",
    "names = ['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles']\n",
    "features_dict = {}\n",
    "interval = 1\n",
    "type_ = 'cqt'  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for n_cqt in n_cqt_list:\n",
    "\t# Save the features to a file\n",
    "\tstoring_name = f'full_data_{interval}s_{sr}hz_{n_cqt}{type_}'  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "\n",
    "\tif os.path.exists(FEATURES_RAW_DIR + storing_name + '.npy'):\n",
    "\t\tprint('The features have already been extracted')\n",
    "\t\t\n",
    "\telse:\n",
    "\t\tfor i, PATH_ in enumerate(PATHS):\n",
    "\t\t\t\n",
    "\t\t\tprint(f'Extracting features from {PATH_}')\n",
    "\t\t\tfeatures = extract_features(PATH_, label = i, frame_length = interval, n_cqt=n_cqt, get_mfcc=False, get_chroma=False, get_cqt=True)\n",
    "\t\t\t\n",
    "\t\t\t# Stack the features into a single tensor\n",
    "\t\t\tfeatures = torch.cat(features, dim=0).numpy()\n",
    "\t\t\tprint(f'The shape of the {PATH_} features tensor is: {features.shape}')\n",
    "\t\t\t\n",
    "\t\t\tX = features[:,:-2]\n",
    "\t\t\ty = features[:,-2]\n",
    "\t\t\tfilename = features[:,-1]\n",
    "\t\t\t\n",
    "\t\t\tlocal_dict = {'X': X, 'y': y, 'filename': filename}\n",
    "\t\t\t\n",
    "\t\t\tfeatures_dict[names[i]] = local_dict\n",
    "\t\t\t\t\n",
    "\t\t# Save the features to a file\n",
    "\t\tnp.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\t\t\t\t\n",
    "\t\tprint('Features extracted and saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Features Extraction\n",
    "- **MFCC (Mel-Frequency Cepstral Coefficients)**: n_mfcc chosen by the user\n",
    "- **Chroma STFT**: 12 coefficients\n",
    "- **CQT (Constant-Q Transform)**: n_cqt chosen by the user\n",
    "- **RMS (Root Mean Square) Energy**: 1 coefficient\n",
    "- **Spectral Centroid**: 1 coefficient\n",
    "- **Spectral Bandwidth**: 1 coefficient\n",
    "- **Spectral Roll-off**: 1 coefficient\n",
    "- **Zero Crossing Rate**: 1 coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES EXTRACTION\n",
    "names = ['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles']\n",
    "features_dict = {}\n",
    "interval = 1\n",
    "n_mfcc = 30 # 30, 120\n",
    "n_cqt = 70 # 30, 70\n",
    "\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "# Save the features to a file\n",
    "storing_name = f'full_data_{interval}s_{sr}hz_{n_mfcc}mfcc_{n_cqt}cqt_12chroma'  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "\n",
    "if os.path.exists(FEATURES_RAW_DIR + storing_name + '.npy'):\n",
    "     print('The features have already been extracted')\n",
    "     \n",
    "else:\n",
    "     for i, PATH_ in enumerate(PATHS):\n",
    "          \n",
    "          print(f'Extracting features from {PATH_}')\n",
    "          features = utils.extract_features(PATH_, label = i, frame_length = interval, n_mfcc=n_mfcc, n_cqt=n_cqt)\n",
    "          \n",
    "          # Stack the features into a single tensor\n",
    "          features = torch.cat(features, dim=0).numpy()\n",
    "          print(f'The shape of the {PATH_} features tensor is: {features.shape}')\n",
    "          \n",
    "          X = features[:,:-2]\n",
    "          y = features[:,-2]\n",
    "          filename = features[:,-1]\n",
    "          \n",
    "          local_dict = {'X': X, 'y': y, 'filename': filename}\n",
    "          \n",
    "          features_dict[names[i]] = local_dict\n",
    "               \n",
    "     # Save the features to a file\n",
    "     np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "               \n",
    "     print('Features extracted and saved')\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features and check the shape\n",
    "features_dict = np.load(FEATURES_RAW_DIR + storing_name + '.npy', allow_pickle=True).item()\n",
    "for key in features_dict.keys():\n",
    "\tprint(f'The shape of the {key} features tensor is: {features_dict[key][\"X\"].shape}')\n",
    "\tprint(f'The shape of the {key} labels tensor is: {features_dict[key][\"y\"].shape}')\n",
    "\tprint(f'The shape of the {key} filenames tensor is: {features_dict[key][\"filename\"].shape}')\n",
    "\tprint('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for key in features_dict.keys():\n",
    "\ts += features_dict[key][\"X\"].shape[0]\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
