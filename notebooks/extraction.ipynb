{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Notebook\n",
    "---\n",
    "\n",
    "This notebook is used to extract features from the data. The audio is divided into windows of 1 second. The features extracted from each audio window are:\n",
    "- **MFCC (Mel-Frequency Cepstral Coefficients)**: n_mfcc chosen by the user\n",
    "- **Chroma STFT**: 12 coefficients\n",
    "- **CQT (Constant-Q Transform)**: n_cqt chosen by the user\n",
    "- **RMS (Root Mean Square) Energy**: 1 coefficient\n",
    "- **Spectral Centroid**: 1 coefficient\n",
    "- **Spectral Bandwidth**: 1 coefficient\n",
    "- **Spectral Roll-off**: 1 coefficient\n",
    "- **Zero Crossing Rate**: 1 coefficient\n",
    "\n",
    "#### Sections:\n",
    "- [Feature Extraction](#Feature-Extraction)\n",
    "  - [Specific Features Extraction](#Specific-Features-Extraction)\n",
    "  - [All Features Extraction](#All-Features-Extraction)\n",
    "\n",
    "  \n",
    "#### Findings:\n",
    "- We have highly unbalanced classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/Users/andreaalberti/Desktop/Public_Projects/advanced-biomedical-project/notebooks/utils.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import all the functions\n",
    "import utils as utils\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import importlib\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "# import the utils module\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n",
       "\n",
       "# -------- tqdm DARK THEME --------\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>\n",
    "\n",
    "# -------- tqdm DARK THEME --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "#sr = ''\n",
    "sr = 4000\n",
    "\n",
    "# set the paths to data\n",
    "BASE_DIR = '../dataset/'\n",
    "ARTIFACTS_DIR = BASE_DIR + f'artifacts_{sr}/'\n",
    "EXTRAHLS_DIR = BASE_DIR + f'extrahls_{sr}/'\n",
    "MURMURS_DIR = BASE_DIR + f'murmurs_{sr}/'\n",
    "NORMALS_DIR = BASE_DIR + f'normals_{sr}/'\n",
    "EXTRASTOLES_DIR = BASE_DIR + f'extrastoles_{sr}/'\n",
    "\n",
    "# paths to save the features\n",
    "FEATURES_RAW_DIR = '../features/raw/'\n",
    "#FEATURES_RAW_DIR = \"../features/balanced/priori/\"\n",
    "\n",
    "PATHS = [ARTIFACTS_DIR, EXTRAHLS_DIR, MURMURS_DIR, NORMALS_DIR, EXTRASTOLES_DIR]\n",
    "\n",
    "# REMOVE THE AUGEMENTED SAMPLES WHEN EXTRACTING BASE RAW FEATURES\n",
    "# for path in PATHS:\n",
    "#      remove_generated_samples(path, 'USERAUGMENTED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Features Extraction\n",
    "- **MFCC (Mel-Frequency Cepstral Coefficients)**: n_mfcc chosen by the user\n",
    "- **Chroma STFT**: 12 coefficients\n",
    "- **CQT (Constant-Q Transform)**: n_cqt chosen by the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(\n",
    "    dir_path: str,\n",
    "    label: str,\n",
    "    frame_length: float,\n",
    "    sample_rate: int = 44100,\n",
    "    n_mfcc: int = 13,\n",
    "    melkwargs: dict = {},\n",
    "    n_cqt: int = 84,\n",
    "    get_mfcc: bool = True,\n",
    "    get_chroma: bool = True,\n",
    "    get_cqt: bool = True,\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Extracts audio features (MFCC, chroma, RMS, spectral centroid, spectral bandwidth, spectral rolloff, zero-crossing rate)\n",
    "    from audio files in the specified directory.\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): The path to the directory containing audio files.\n",
    "        label (str): The label associated with the extracted features.\n",
    "        frame_length: The frame length for feature extraction.\n",
    "        sample_rate (int, optional): The sample rate of the audio files. Defaults to 44100 Hz.\n",
    "        n_mfcc (int, optional): The number of Mel-frequency cepstral coefficients (MFCCs) to extract. Defaults to 13.\n",
    "        melkwargs (dict, optional): Additional arguments for Mel spectrogram computation.\n",
    "        n_cqt (int, optional): The number of constant-Q transform (CQT) bins to extract. Defaults to 84.\n",
    "        \n",
    "    Returns:\n",
    "        list: A list containing tensors of extracted features for each audio file.\n",
    "    \"\"\"\n",
    "    filenames = os.listdir(dir_path)\n",
    "    filenames = [file for file in filenames if not file.startswith(\".\")]\n",
    "    frame_length = int(1 / frame_length)\n",
    "\n",
    "    features = []  # List to store the features for all files\n",
    "\n",
    "    for file in tqdm(filenames, desc=f\"Extraction in progress\"):\n",
    "        audio, orig_sample_rate = torchaudio.load(os.path.join(dir_path, file))\n",
    "        orig_sample_rate_tmp = int(orig_sample_rate / frame_length)\n",
    "        audio_length = int(max(audio[0].shape) / (orig_sample_rate_tmp))\n",
    "\n",
    "        sample_rate = orig_sample_rate\n",
    "\n",
    "        # Reduce the audio from stereo to mono if needed\n",
    "        if audio.shape[0] > 1:\n",
    "            print(f\"Converting stereo audio to mono for {file}...\")\n",
    "            audio = torch.mean(audio, dim=0).reshape(1, -1)\n",
    "\n",
    "        features_local = []  # List to store the MFCC features for each file\n",
    "\n",
    "        for i in range(audio_length):\n",
    "            # Lazy load the audio, one sec at a time, to avoid memory issues\n",
    "            audio_mono = utils.slicing(\n",
    "                audio,\n",
    "                offset=int(sample_rate / frame_length * i),\n",
    "                num_frames=int(sample_rate / frame_length * (i + 1)),\n",
    "            )\n",
    "\n",
    "            # Get the MFCC features\n",
    "            if get_mfcc:\n",
    "                mfcc_features_tmp = utils.extract_mfcc(audio_mono, sample_rate, n_mfcc, melkwargs)\n",
    "            if get_chroma:\n",
    "                chroma_stft = utils.extract_chroma_stft(audio_mono, sample_rate)\n",
    "            if get_cqt:\n",
    "                cqt = utils.extract_cqt(audio_mono, sample_rate=sample_rate, n_cqt=n_cqt)\n",
    "\n",
    "          #   rms = extract_rms(audio_mono)\n",
    "          #   spec_cent = extract_spectral_centroid(audio_mono, sample_rate)\n",
    "          #   spec_bw = extract_spectral_bandwidth(audio_mono, sample_rate)\n",
    "          #   rolloff = extract_spectral_rolloff(audio_mono, sample_rate)\n",
    "          #   zcr = extract_zero_crossing_rate(audio_mono)\n",
    "\n",
    "            \n",
    "            # Concatenate the features\n",
    "            if get_mfcc:\n",
    "                features_tmp = mfcc_features_tmp\n",
    "            if get_chroma:\n",
    "                features_tmp = chroma_stft\n",
    "            if get_cqt:\n",
    "                features_tmp = cqt\n",
    "            \n",
    "            if get_mfcc and get_chroma:\n",
    "                features_tmp = torch.cat(\n",
    "                    (mfcc_features_tmp, chroma_stft),\n",
    "                    dim=0,\n",
    "                )\n",
    "            if get_mfcc and get_cqt:\n",
    "                features_tmp = torch.cat(\n",
    "                    (mfcc_features_tmp, cqt),\n",
    "                    dim=0,\n",
    "                )\n",
    "            if get_chroma and get_cqt:\n",
    "                features_tmp = torch.cat(\n",
    "                    (chroma_stft, cqt),\n",
    "                    dim=0,\n",
    "                )\n",
    "            if get_mfcc and get_chroma and get_cqt:\n",
    "                features_tmp = torch.cat(\n",
    "                    (mfcc_features_tmp, chroma_stft, cqt),\n",
    "                    dim=0,\n",
    "                )\n",
    "            if not get_mfcc and not get_chroma and not get_cqt:\n",
    "                features_tmp = torch.tensor([])\n",
    "\n",
    "            features_local.append(features_tmp)\n",
    "\n",
    "\n",
    "        # If features_local is empty, skip the file\n",
    "        if features_local == []:\n",
    "            print(f\"No features extracted for {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Stack the MFCC features into a single tensor\n",
    "        features_local = torch.stack(features_local, dim=0)\n",
    "\n",
    "        # Attach the label in the last column\n",
    "        features_local = torch.cat(\n",
    "            (features_local, torch.ones(features_local.shape[0], 1) * label), dim=1\n",
    "        )\n",
    "\n",
    "        # Attach the filename index in the last column\n",
    "        features_local = torch.cat(\n",
    "            (\n",
    "                features_local,\n",
    "                torch.full((features_local.shape[0], 1), filenames.index(file)),\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        features.append(features_local)\n",
    "\n",
    "    print(\"Finished processing all files.\\n\")\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96741250f0654f2b870f09d6d2601823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_17.wav...\n",
      "Converting stereo audio to mono for artifact_2023_16.wav...\n",
      "Converting stereo audio to mono for artifact_2023_14.wav...\n",
      "Converting stereo audio to mono for artifact_2023_15.wav...\n",
      "Converting stereo audio to mono for artifact_2023_39.wav...\n",
      "Converting stereo audio to mono for artifact_2023_11.wav...\n",
      "Converting stereo audio to mono for artifact_2023_38.wav...\n",
      "Converting stereo audio to mono for artifact_2023_12.wav...\n",
      "Converting stereo audio to mono for artifact_2023_13.wav...\n",
      "Converting stereo audio to mono for artifact_2023_49.wav...\n",
      "Converting stereo audio to mono for artifact_2023_41.wav...\n",
      "Converting stereo audio to mono for artifact_2023_40.wav...\n",
      "Converting stereo audio to mono for artifact_2023_42.wav...\n",
      "Converting stereo audio to mono for artifact_2023_43.wav...\n",
      "Converting stereo audio to mono for artifact_2023_47.wav...\n",
      "Converting stereo audio to mono for artifact_2023_46.wav...\n",
      "Converting stereo audio to mono for artifact_2023_50.wav...\n",
      "Converting stereo audio to mono for artifact_2023_44.wav...\n",
      "Converting stereo audio to mono for artifact_2023_45.wav...\n",
      "Converting stereo audio to mono for artifact_2023_51.wav...\n",
      "Converting stereo audio to mono for artifact_2023_36.wav...\n",
      "Converting stereo audio to mono for artifact_2023_22.wav...\n",
      "Converting stereo audio to mono for artifact_2023_4.wav...\n",
      "Converting stereo audio to mono for artifact_2023_5.wav...\n",
      "Converting stereo audio to mono for artifact_2023_23.wav...\n",
      "Converting stereo audio to mono for artifact_2023_37.wav...\n",
      "Converting stereo audio to mono for artifact_2023_21.wav...\n",
      "Converting stereo audio to mono for artifact_2023_35.wav...\n",
      "Converting stereo audio to mono for artifact_2023_7.wav...\n",
      "Converting stereo audio to mono for artifact_2023_6.wav...\n",
      "Converting stereo audio to mono for artifact_2023_34.wav...\n",
      "Converting stereo audio to mono for artifact_2023_20.wav...\n",
      "Converting stereo audio to mono for artifact_2023_18.wav...\n",
      "Converting stereo audio to mono for artifact_2023_24.wav...\n",
      "Converting stereo audio to mono for artifact_2023_2.wav...\n",
      "Converting stereo audio to mono for artifact_2023_25.wav...\n",
      "Converting stereo audio to mono for artifact_2023_19.wav...\n",
      "Converting stereo audio to mono for artifact_2023_33.wav...\n",
      "Converting stereo audio to mono for artifact_2023_1.wav...\n",
      "Converting stereo audio to mono for artifact_2023_0.wav...\n",
      "Converting stereo audio to mono for artifact_2023_26.wav...\n",
      "Converting stereo audio to mono for artifact_2023_32.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/artifacts_4000/ features tensor is: (2001, 32)\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c91002ae22a94319bfa2d845167065b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for extrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (124, 32)\n",
      "Extracting features from ../dataset/murmurs_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83cdd80170af4b6db574f4cdab6295ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for murmur__201104021355.wav. Skipping...\n",
      "Converting stereo audio to mono for abnormal_s4_2023_2.wav...\n",
      "No features extracted for murmur__171_1307971016233_E.wav. Skipping...\n",
      "Converting stereo audio to mono for atrial_septal_defect_2023_6.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_1.wav...\n",
      "Converting stereo audio to mono for mitral_stenosis_2023_9.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_0.wav...\n",
      "Converting stereo audio to mono for holosystolic_murmur_2023_7.wav...\n",
      "Converting stereo audio to mono for aortic_stenosis_2023_4.wav...\n",
      "Converting stereo audio to mono for mitral_valve_prolapse_2023_10.wav...\n",
      "Converting stereo audio to mono for innocent_murmur_2023_8.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/murmurs_4000/ features tensor is: (1149, 32)\n",
      "Extracting features from ../dataset/normals_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad848c0a7d947f7b450f87e2696449e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for normal__296_1311682952647_A1.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_3.wav...\n",
      "Converting stereo audio to mono for normal_2023_2.wav...\n",
      "Converting stereo audio to mono for normal_2023_0.wav...\n",
      "Converting stereo audio to mono for normal_2023_1.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/normals_4000/ features tensor is: (2161, 32)\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c444cee7594518a6476a2638599fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (247, 32)\n",
      "Features extracted and saved\n",
      "Extracting features from ../dataset/artifacts_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4312a32341ed4f2baa0b448bfe32f941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_17.wav...\n",
      "Converting stereo audio to mono for artifact_2023_16.wav...\n",
      "Converting stereo audio to mono for artifact_2023_14.wav...\n",
      "Converting stereo audio to mono for artifact_2023_15.wav...\n",
      "Converting stereo audio to mono for artifact_2023_39.wav...\n",
      "Converting stereo audio to mono for artifact_2023_11.wav...\n",
      "Converting stereo audio to mono for artifact_2023_38.wav...\n",
      "Converting stereo audio to mono for artifact_2023_12.wav...\n",
      "Converting stereo audio to mono for artifact_2023_13.wav...\n",
      "Converting stereo audio to mono for artifact_2023_49.wav...\n",
      "Converting stereo audio to mono for artifact_2023_41.wav...\n",
      "Converting stereo audio to mono for artifact_2023_40.wav...\n",
      "Converting stereo audio to mono for artifact_2023_42.wav...\n",
      "Converting stereo audio to mono for artifact_2023_43.wav...\n",
      "Converting stereo audio to mono for artifact_2023_47.wav...\n",
      "Converting stereo audio to mono for artifact_2023_46.wav...\n",
      "Converting stereo audio to mono for artifact_2023_50.wav...\n",
      "Converting stereo audio to mono for artifact_2023_44.wav...\n",
      "Converting stereo audio to mono for artifact_2023_45.wav...\n",
      "Converting stereo audio to mono for artifact_2023_51.wav...\n",
      "Converting stereo audio to mono for artifact_2023_36.wav...\n",
      "Converting stereo audio to mono for artifact_2023_22.wav...\n",
      "Converting stereo audio to mono for artifact_2023_4.wav...\n",
      "Converting stereo audio to mono for artifact_2023_5.wav...\n",
      "Converting stereo audio to mono for artifact_2023_23.wav...\n",
      "Converting stereo audio to mono for artifact_2023_37.wav...\n",
      "Converting stereo audio to mono for artifact_2023_21.wav...\n",
      "Converting stereo audio to mono for artifact_2023_35.wav...\n",
      "Converting stereo audio to mono for artifact_2023_7.wav...\n",
      "Converting stereo audio to mono for artifact_2023_6.wav...\n",
      "Converting stereo audio to mono for artifact_2023_34.wav...\n",
      "Converting stereo audio to mono for artifact_2023_20.wav...\n",
      "Converting stereo audio to mono for artifact_2023_18.wav...\n",
      "Converting stereo audio to mono for artifact_2023_24.wav...\n",
      "Converting stereo audio to mono for artifact_2023_2.wav...\n",
      "Converting stereo audio to mono for artifact_2023_25.wav...\n",
      "Converting stereo audio to mono for artifact_2023_19.wav...\n",
      "Converting stereo audio to mono for artifact_2023_33.wav...\n",
      "Converting stereo audio to mono for artifact_2023_1.wav...\n",
      "Converting stereo audio to mono for artifact_2023_0.wav...\n",
      "Converting stereo audio to mono for artifact_2023_26.wav...\n",
      "Converting stereo audio to mono for artifact_2023_32.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/artifacts_4000/ features tensor is: (2001, 122)\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1e223e1781143b09d44cd10a2b5c39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for extrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (124, 122)\n",
      "Extracting features from ../dataset/murmurs_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ab866ac9c2f41a5a1e3bfd3165594bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for murmur__201104021355.wav. Skipping...\n",
      "Converting stereo audio to mono for abnormal_s4_2023_2.wav...\n",
      "No features extracted for murmur__171_1307971016233_E.wav. Skipping...\n",
      "Converting stereo audio to mono for atrial_septal_defect_2023_6.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_1.wav...\n",
      "Converting stereo audio to mono for mitral_stenosis_2023_9.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_0.wav...\n",
      "Converting stereo audio to mono for holosystolic_murmur_2023_7.wav...\n",
      "Converting stereo audio to mono for aortic_stenosis_2023_4.wav...\n",
      "Converting stereo audio to mono for mitral_valve_prolapse_2023_10.wav...\n",
      "Converting stereo audio to mono for innocent_murmur_2023_8.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/murmurs_4000/ features tensor is: (1149, 122)\n",
      "Extracting features from ../dataset/normals_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500e0c844be3416bacf22c8791658640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for normal__296_1311682952647_A1.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_3.wav...\n",
      "Converting stereo audio to mono for normal_2023_2.wav...\n",
      "Converting stereo audio to mono for normal_2023_0.wav...\n",
      "Converting stereo audio to mono for normal_2023_1.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/normals_4000/ features tensor is: (2161, 122)\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1359212e19c433da94ee3e3c10b07b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (247, 122)\n",
      "Features extracted and saved\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- MFCC -------------------------\n",
    "n_mfcc_list = [30, 120]\n",
    "names = ['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles']\n",
    "features_dict = {}\n",
    "interval = 1\n",
    "type_ = 'mfcc'  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for n_mfcc in n_mfcc_list:\n",
    "\t# Save the features to a file\n",
    "\tstoring_name = f'full_data_{interval}s_{sr}hz_{n_mfcc}{type_}'  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "\n",
    "\tif os.path.exists(FEATURES_RAW_DIR + storing_name + '.npy'):\n",
    "\t\tprint('The features have already been extracted')\n",
    "\t\t\n",
    "\telse:\n",
    "\t\tfor i, PATH_ in enumerate(PATHS):\n",
    "\t\t\t\n",
    "\t\t\tprint(f'Extracting features from {PATH_}')\n",
    "\t\t\tfeatures = extract_features(PATH_, label = i, frame_length = interval, n_mfcc=n_mfcc, get_mfcc=True, get_chroma=False, get_cqt=False)\n",
    "\t\t\t\n",
    "\t\t\t# Stack the features into a single tensor\n",
    "\t\t\tfeatures = torch.cat(features, dim=0).numpy()\n",
    "\t\t\tprint(f'The shape of the {PATH_} features tensor is: {features.shape}')\n",
    "\t\t\t\n",
    "\t\t\tX = features[:,:-2]\n",
    "\t\t\ty = features[:,-2]\n",
    "\t\t\tfilename = features[:,-1]\n",
    "\t\t\t\n",
    "\t\t\tlocal_dict = {'X': X, 'y': y, 'filename': filename}\n",
    "\t\t\t\n",
    "\t\t\tfeatures_dict[names[i]] = local_dict\n",
    "\t\t\t\t\n",
    "\t\t# Save the features to a file\n",
    "\t\tnp.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\t\t\t\t\n",
    "\t\tprint('Features extracted and saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf877f85a72344db914b2f59561c3bef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_17.wav...\n",
      "Converting stereo audio to mono for artifact_2023_16.wav...\n",
      "Converting stereo audio to mono for artifact_2023_14.wav...\n",
      "Converting stereo audio to mono for artifact_2023_15.wav...\n",
      "Converting stereo audio to mono for artifact_2023_39.wav...\n",
      "Converting stereo audio to mono for artifact_2023_11.wav...\n",
      "Converting stereo audio to mono for artifact_2023_38.wav...\n",
      "Converting stereo audio to mono for artifact_2023_12.wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_13.wav...\n",
      "Converting stereo audio to mono for artifact_2023_49.wav...\n",
      "Converting stereo audio to mono for artifact_2023_41.wav...\n",
      "Converting stereo audio to mono for artifact_2023_40.wav...\n",
      "Converting stereo audio to mono for artifact_2023_42.wav...\n",
      "Converting stereo audio to mono for artifact_2023_43.wav...\n",
      "Converting stereo audio to mono for artifact_2023_47.wav...\n",
      "Converting stereo audio to mono for artifact_2023_46.wav...\n",
      "Converting stereo audio to mono for artifact_2023_50.wav...\n",
      "Converting stereo audio to mono for artifact_2023_44.wav...\n",
      "Converting stereo audio to mono for artifact_2023_45.wav...\n",
      "Converting stereo audio to mono for artifact_2023_51.wav...\n",
      "Converting stereo audio to mono for artifact_2023_36.wav...\n",
      "Converting stereo audio to mono for artifact_2023_22.wav...\n",
      "Converting stereo audio to mono for artifact_2023_4.wav...\n",
      "Converting stereo audio to mono for artifact_2023_5.wav...\n",
      "Converting stereo audio to mono for artifact_2023_23.wav...\n",
      "Converting stereo audio to mono for artifact_2023_37.wav...\n",
      "Converting stereo audio to mono for artifact_2023_21.wav...\n",
      "Converting stereo audio to mono for artifact_2023_35.wav...\n",
      "Converting stereo audio to mono for artifact_2023_7.wav...\n",
      "Converting stereo audio to mono for artifact_2023_6.wav...\n",
      "Converting stereo audio to mono for artifact_2023_34.wav...\n",
      "Converting stereo audio to mono for artifact_2023_20.wav...\n",
      "Converting stereo audio to mono for artifact_2023_18.wav...\n",
      "Converting stereo audio to mono for artifact_2023_24.wav...\n",
      "Converting stereo audio to mono for artifact_2023_2.wav...\n",
      "Converting stereo audio to mono for artifact_2023_25.wav...\n",
      "Converting stereo audio to mono for artifact_2023_19.wav...\n",
      "Converting stereo audio to mono for artifact_2023_33.wav...\n",
      "Converting stereo audio to mono for artifact_2023_1.wav...\n",
      "Converting stereo audio to mono for artifact_2023_0.wav...\n",
      "Converting stereo audio to mono for artifact_2023_26.wav...\n",
      "Converting stereo audio to mono for artifact_2023_32.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/artifacts_4000/ features tensor is: (2001, 14)\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d61b726669c74e1390d6f6369b81a6ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for extrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (124, 14)\n",
      "Extracting features from ../dataset/murmurs_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "233fcdc8c4fa4ec19c642b945bbc198d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for murmur__201104021355.wav. Skipping...\n",
      "Converting stereo audio to mono for abnormal_s4_2023_2.wav...\n",
      "No features extracted for murmur__171_1307971016233_E.wav. Skipping...\n",
      "Converting stereo audio to mono for atrial_septal_defect_2023_6.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_1.wav...\n",
      "Converting stereo audio to mono for mitral_stenosis_2023_9.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_0.wav...\n",
      "Converting stereo audio to mono for holosystolic_murmur_2023_7.wav...\n",
      "Converting stereo audio to mono for aortic_stenosis_2023_4.wav...\n",
      "Converting stereo audio to mono for mitral_valve_prolapse_2023_10.wav...\n",
      "Converting stereo audio to mono for innocent_murmur_2023_8.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/murmurs_4000/ features tensor is: (1149, 14)\n",
      "Extracting features from ../dataset/normals_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "611ee0837b8d4b16bf2714e15747e2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for normal__296_1311682952647_A1.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_3.wav...\n",
      "Converting stereo audio to mono for normal_2023_2.wav...\n",
      "Converting stereo audio to mono for normal_2023_0.wav...\n",
      "Converting stereo audio to mono for normal_2023_1.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/normals_4000/ features tensor is: (2161, 14)\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6acfc8293d65473ba8479c63101cdcf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (247, 14)\n",
      "Features extracted and saved\n",
      "The features have already been extracted\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- CHROMA -------------------------\n",
    "names = ['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles']\n",
    "features_dict = {}\n",
    "interval = 1\n",
    "n_features = 12\n",
    "type_ = 'chroma'  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for n_mfcc in n_mfcc_list:\n",
    "\t# Save the features to a file\n",
    "\tstoring_name = f'full_data_{interval}s_{sr}hz_{n_features}{type_}'  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "\n",
    "\tif os.path.exists(FEATURES_RAW_DIR + storing_name + '.npy'):\n",
    "\t\tprint('The features have already been extracted')\n",
    "\t\t\n",
    "\telse:\n",
    "\t\tfor i, PATH_ in enumerate(PATHS):\n",
    "\t\t\t\n",
    "\t\t\tprint(f'Extracting features from {PATH_}')\n",
    "\t\t\tfeatures = extract_features(PATH_, label = i, frame_length = interval, n_mfcc=n_mfcc, get_mfcc=False, get_chroma=True, get_cqt=False)\n",
    "\t\t\t\n",
    "\t\t\t# Stack the features into a single tensor\n",
    "\t\t\tfeatures = torch.cat(features, dim=0).numpy()\n",
    "\t\t\tprint(f'The shape of the {PATH_} features tensor is: {features.shape}')\n",
    "\t\t\t\n",
    "\t\t\tX = features[:,:-2]\n",
    "\t\t\ty = features[:,-2]\n",
    "\t\t\tfilename = features[:,-1]\n",
    "\t\t\t\n",
    "\t\t\tlocal_dict = {'X': X, 'y': y, 'filename': filename}\n",
    "\t\t\t\n",
    "\t\t\tfeatures_dict[names[i]] = local_dict\n",
    "\t\t\t\t\n",
    "\t\t# Save the features to a file\n",
    "\t\tnp.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\t\t\t\t\n",
    "\t\tprint('Features extracted and saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The features have already been extracted\n",
      "Extracting features from ../dataset/artifacts_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f46c02885ac04b21b7b1265f8b517cd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_17.wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/librosa/core/spectrum.py:266: UserWarning: n_fft=128 is too large for input signal of length=125\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_16.wav...\n",
      "Converting stereo audio to mono for artifact_2023_14.wav...\n",
      "Converting stereo audio to mono for artifact_2023_15.wav...\n",
      "Converting stereo audio to mono for artifact_2023_39.wav...\n",
      "Converting stereo audio to mono for artifact_2023_11.wav...\n",
      "Converting stereo audio to mono for artifact_2023_38.wav...\n",
      "Converting stereo audio to mono for artifact_2023_12.wav...\n",
      "Converting stereo audio to mono for artifact_2023_13.wav...\n",
      "Converting stereo audio to mono for artifact_2023_49.wav...\n",
      "Converting stereo audio to mono for artifact_2023_41.wav...\n",
      "Converting stereo audio to mono for artifact_2023_40.wav...\n",
      "Converting stereo audio to mono for artifact_2023_42.wav...\n",
      "Converting stereo audio to mono for artifact_2023_43.wav...\n",
      "Converting stereo audio to mono for artifact_2023_47.wav...\n",
      "Converting stereo audio to mono for artifact_2023_46.wav...\n",
      "Converting stereo audio to mono for artifact_2023_50.wav...\n",
      "Converting stereo audio to mono for artifact_2023_44.wav...\n",
      "Converting stereo audio to mono for artifact_2023_45.wav...\n",
      "Converting stereo audio to mono for artifact_2023_51.wav...\n",
      "Converting stereo audio to mono for artifact_2023_36.wav...\n",
      "Converting stereo audio to mono for artifact_2023_22.wav...\n",
      "Converting stereo audio to mono for artifact_2023_4.wav...\n",
      "Converting stereo audio to mono for artifact_2023_5.wav...\n",
      "Converting stereo audio to mono for artifact_2023_23.wav...\n",
      "Converting stereo audio to mono for artifact_2023_37.wav...\n",
      "Converting stereo audio to mono for artifact_2023_21.wav...\n",
      "Converting stereo audio to mono for artifact_2023_35.wav...\n",
      "Converting stereo audio to mono for artifact_2023_7.wav...\n",
      "Converting stereo audio to mono for artifact_2023_6.wav...\n",
      "Converting stereo audio to mono for artifact_2023_34.wav...\n",
      "Converting stereo audio to mono for artifact_2023_20.wav...\n",
      "Converting stereo audio to mono for artifact_2023_18.wav...\n",
      "Converting stereo audio to mono for artifact_2023_24.wav...\n",
      "Converting stereo audio to mono for artifact_2023_2.wav...\n",
      "Converting stereo audio to mono for artifact_2023_25.wav...\n",
      "Converting stereo audio to mono for artifact_2023_19.wav...\n",
      "Converting stereo audio to mono for artifact_2023_33.wav...\n",
      "Converting stereo audio to mono for artifact_2023_1.wav...\n",
      "Converting stereo audio to mono for artifact_2023_0.wav...\n",
      "Converting stereo audio to mono for artifact_2023_26.wav...\n",
      "Converting stereo audio to mono for artifact_2023_32.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/artifacts_4000/ features tensor is: (2001, 72)\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5077b15925148f3bc67c19db956befe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for extrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (124, 72)\n",
      "Extracting features from ../dataset/murmurs_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96fa972b20a6435b8f69d4e51bcc27eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for murmur__201104021355.wav. Skipping...\n",
      "Converting stereo audio to mono for abnormal_s4_2023_2.wav...\n",
      "No features extracted for murmur__171_1307971016233_E.wav. Skipping...\n",
      "Converting stereo audio to mono for atrial_septal_defect_2023_6.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_1.wav...\n",
      "Converting stereo audio to mono for mitral_stenosis_2023_9.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_0.wav...\n",
      "Converting stereo audio to mono for holosystolic_murmur_2023_7.wav...\n",
      "Converting stereo audio to mono for aortic_stenosis_2023_4.wav...\n",
      "Converting stereo audio to mono for mitral_valve_prolapse_2023_10.wav...\n",
      "Converting stereo audio to mono for innocent_murmur_2023_8.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/murmurs_4000/ features tensor is: (1149, 72)\n",
      "Extracting features from ../dataset/normals_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91705c0e885a4ce293955a38c2067db0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for normal__296_1311682952647_A1.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_3.wav...\n",
      "Converting stereo audio to mono for normal_2023_2.wav...\n",
      "Converting stereo audio to mono for normal_2023_0.wav...\n",
      "Converting stereo audio to mono for normal_2023_1.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/normals_4000/ features tensor is: (2161, 72)\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec499bce64954c03854321987b9488d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (247, 72)\n",
      "Features extracted and saved\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- CQT -------------------------\n",
    "n_cqt_list = [30, 70]\n",
    "names = ['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles']\n",
    "features_dict = {}\n",
    "interval = 1\n",
    "type_ = 'cqt'  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for n_cqt in n_cqt_list:\n",
    "\t# Save the features to a file\n",
    "\tstoring_name = f'full_data_{interval}s_{sr}hz_{n_cqt}{type_}'  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "\n",
    "\tif os.path.exists(FEATURES_RAW_DIR + storing_name + '.npy'):\n",
    "\t\tprint('The features have already been extracted')\n",
    "\t\t\n",
    "\telse:\n",
    "\t\tfor i, PATH_ in enumerate(PATHS):\n",
    "\t\t\t\n",
    "\t\t\tprint(f'Extracting features from {PATH_}')\n",
    "\t\t\tfeatures = extract_features(PATH_, label = i, frame_length = interval, n_cqt=n_cqt, get_mfcc=False, get_chroma=False, get_cqt=True)\n",
    "\t\t\t\n",
    "\t\t\t# Stack the features into a single tensor\n",
    "\t\t\tfeatures = torch.cat(features, dim=0).numpy()\n",
    "\t\t\tprint(f'The shape of the {PATH_} features tensor is: {features.shape}')\n",
    "\t\t\t\n",
    "\t\t\tX = features[:,:-2]\n",
    "\t\t\ty = features[:,-2]\n",
    "\t\t\tfilename = features[:,-1]\n",
    "\t\t\t\n",
    "\t\t\tlocal_dict = {'X': X, 'y': y, 'filename': filename}\n",
    "\t\t\t\n",
    "\t\t\tfeatures_dict[names[i]] = local_dict\n",
    "\t\t\t\t\n",
    "\t\t# Save the features to a file\n",
    "\t\tnp.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\t\t\t\t\n",
    "\t\tprint('Features extracted and saved')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Features Extraction\n",
    "- **MFCC (Mel-Frequency Cepstral Coefficients)**: n_mfcc chosen by the user\n",
    "- **Chroma STFT**: 12 coefficients\n",
    "- **CQT (Constant-Q Transform)**: n_cqt chosen by the user\n",
    "- **RMS (Root Mean Square) Energy**: 1 coefficient\n",
    "- **Spectral Centroid**: 1 coefficient\n",
    "- **Spectral Bandwidth**: 1 coefficient\n",
    "- **Spectral Roll-off**: 1 coefficient\n",
    "- **Zero Crossing Rate**: 1 coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES EXTRACTION\n",
    "names = ['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles']\n",
    "features_dict = {}\n",
    "interval = 1\n",
    "n_mfcc = 30\n",
    "num_feat = 30\n",
    "type_ = 'mfcc'  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "# Save the features to a file\n",
    "storing_name = f'full_data_{interval}s_{sr}hz_{num_feat}{type_}'  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "\n",
    "if os.path.exists(FEATURES_RAW_DIR + storing_name + '.npy'):\n",
    "     print('The features have already been extracted')\n",
    "     \n",
    "else:\n",
    "     for i, PATH_ in enumerate(PATHS):\n",
    "          \n",
    "          print(f'Extracting features from {PATH_}')\n",
    "          features = utils.extract_features(PATH_, label = i, frame_length = interval, n_mfcc=n_mfcc)\n",
    "          \n",
    "          # Stack the features into a single tensor\n",
    "          features = torch.cat(features, dim=0).numpy()\n",
    "          print(f'The shape of the {PATH_} features tensor is: {features.shape}')\n",
    "          \n",
    "          X = features[:,:-2]\n",
    "          y = features[:,-2]\n",
    "          filename = features[:,-1]\n",
    "          \n",
    "          local_dict = {'X': X, 'y': y, 'filename': filename}\n",
    "          \n",
    "          features_dict[names[i]] = local_dict\n",
    "               \n",
    "     # Save the features to a file\n",
    "     np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "               \n",
    "     print('Features extracted and saved')\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features and check the shape\n",
    "features_dict = np.load(FEATURES_RAW_DIR + storing_name + '.npy', allow_pickle=True).item()\n",
    "for key in features_dict.keys():\n",
    "\tprint(f'The shape of the {key} features tensor is: {features_dict[key][\"X\"].shape}')\n",
    "\tprint(f'The shape of the {key} labels tensor is: {features_dict[key][\"y\"].shape}')\n",
    "\tprint(f'The shape of the {key} filenames tensor is: {features_dict[key][\"filename\"].shape}')\n",
    "\tprint('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for key in features_dict.keys():\n",
    "\ts += features_dict[key][\"X\"].shape[0]\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
