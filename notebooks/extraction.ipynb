{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Notebook\n",
    "---\n",
    "\n",
    "This notebook is used to extract features from the data. The audio is divided into windows of 1 second. The features extracted from each audio window are:\n",
    "- MFCC (Mel-Frequency Cepstral Coefficients): 20 coefficients\n",
    "- Chroma STFT: 1 coefficient\n",
    "- RMS (Root Mean Square) Energy: 1 coefficient\n",
    "- Spectral Centroid: 1 coefficient\n",
    "- Spectral Bandwidth: 1 coefficient\n",
    "- Spectral Roll-off: 1 coefficient\n",
    "- Zero Crossing Rate: 1 coefficient\n",
    "  \n",
    "#### Findings:\n",
    "- We have highly unbalanced classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the functions\n",
    "from utils import *\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".cell-output-ipywidget-background {\n",
       "    background-color: transparent !important;\n",
       "}\n",
       ":root {\n",
       "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
       "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
       "}  \n",
       "</style>\n",
       "\n",
       "# -------- tqdm DARK THEME --------\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>\n",
    "\n",
    "# -------- tqdm DARK THEME --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the paths to data\n",
    "BASE_DIR = '../dataset/'\n",
    "ARTIFACTS_DIR = BASE_DIR + 'artifacts/'\n",
    "EXTRAHLS_DIR = BASE_DIR + 'extrahls/'\n",
    "MURMURS_DIR = BASE_DIR + 'murmurs/'\n",
    "NORMALS_DIR = BASE_DIR + 'normals/'\n",
    "EXTRASTOLES_DIR = BASE_DIR + 'extrastoles/'\n",
    "\n",
    "# paths to save the features\n",
    "#FEATURES_RAW_DIR = '../features/raw/'\n",
    "FEATURES_RAW_DIR = \"../features/balanced/priori/\"\n",
    "\n",
    "PATHS = [ARTIFACTS_DIR, EXTRAHLS_DIR, MURMURS_DIR, NORMALS_DIR, EXTRASTOLES_DIR]\n",
    "\n",
    "# REMOVE THE AUGEMENTED SAMPLES WHEN EXTRACTING BASE RAW FEATURES\n",
    "# for path in PATHS:\n",
    "#      remove_generated_samples(path, 'USERAUGMENTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f6d80509a2744339b1b7ea4fbdc5bd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_17.wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/torchaudio/functional/functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_16.wav...\n",
      "Converting stereo audio to mono for artifact_2023_14.wav...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_15.wav...\n",
      "Converting stereo audio to mono for artifact_2023_39.wav...\n",
      "Converting stereo audio to mono for artifact_2023_11.wav...\n",
      "Converting stereo audio to mono for artifact_2023_38.wav...\n",
      "Converting stereo audio to mono for artifact_2023_12.wav...\n",
      "Converting stereo audio to mono for artifact_2023_13.wav...\n",
      "Converting stereo audio to mono for artifact_2023_41.wav...\n",
      "Converting stereo audio to mono for artifact_2023_40.wav...\n",
      "Converting stereo audio to mono for artifact_2023_42.wav...\n",
      "Converting stereo audio to mono for artifact_2023_43.wav...\n",
      "Converting stereo audio to mono for artifact_2023_46.wav...\n",
      "Converting stereo audio to mono for artifact_2023_44.wav...\n",
      "Converting stereo audio to mono for artifact_2023_45.wav...\n",
      "Converting stereo audio to mono for artifact_2023_36.wav...\n",
      "Converting stereo audio to mono for artifact_2023_22.wav...\n",
      "Converting stereo audio to mono for artifact_2023_4.wav...\n",
      "Converting stereo audio to mono for artifact_2023_5.wav...\n",
      "Converting stereo audio to mono for artifact_2023_23.wav...\n",
      "Converting stereo audio to mono for artifact_2023_37.wav...\n",
      "Converting stereo audio to mono for artifact_2023_21.wav...\n",
      "Converting stereo audio to mono for artifact_2023_35.wav...\n",
      "Converting stereo audio to mono for artifact_2023_6.wav...\n",
      "Converting stereo audio to mono for artifact_2023_34.wav...\n",
      "Converting stereo audio to mono for artifact_2023_20.wav...\n",
      "Converting stereo audio to mono for artifact_2023_18.wav...\n",
      "Converting stereo audio to mono for artifact_2023_24.wav...\n",
      "Converting stereo audio to mono for artifact_2023_2.wav...\n",
      "Converting stereo audio to mono for artifact_2023_25.wav...\n",
      "Converting stereo audio to mono for artifact_2023_19.wav...\n",
      "Converting stereo audio to mono for artifact_2023_33.wav...\n",
      "Converting stereo audio to mono for artifact_2023_1.wav...\n",
      "Converting stereo audio to mono for artifact_2023_0.wav...\n",
      "Converting stereo audio to mono for artifact_2023_26.wav...\n",
      "Converting stereo audio to mono for artifact_2023_32.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/artifacts/ features tensor is: (1199, 28)\n",
      "Extracting features from ../dataset/extrahls/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0615511d1fa42479bf6ca6cd973399b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for speed_13USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for pitch_44USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for speed_20USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for pitch_12USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for extrahls__201104021355.wav. Skipping...\n",
      "No features extracted for noisy_3USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for speed_28USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "No features extracted for speed_21USERAUGMENTEDextrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls/ features tensor is: (883, 28)\n",
      "Extracting features from ../dataset/murmurs/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90672b7188504abc8b79365278c012f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for murmur__201104021355.wav. Skipping...\n",
      "Converting stereo audio to mono for abnormal_s4_2023_2.wav...\n",
      "No features extracted for murmur__171_1307971016233_E.wav. Skipping...\n",
      "Converting stereo audio to mono for atrial_septal_defect_2023_6.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_1.wav...\n",
      "Converting stereo audio to mono for mitral_stenosis_2023_9.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_0.wav...\n",
      "Converting stereo audio to mono for holosystolic_murmur_2023_7.wav...\n",
      "Converting stereo audio to mono for aortic_stenosis_2023_4.wav...\n",
      "Converting stereo audio to mono for mitral_valve_prolapse_2023_10.wav...\n",
      "Converting stereo audio to mono for innocent_murmur_2023_8.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/murmurs/ features tensor is: (1149, 28)\n",
      "Extracting features from ../dataset/normals/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "add9cd4d2df24d3da7ab3b226766dc5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for normal__296_1311682952647_A1.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_3.wav...\n",
      "Converting stereo audio to mono for normal_2023_2.wav...\n",
      "Converting stereo audio to mono for normal_2023_0.wav...\n",
      "Converting stereo audio to mono for normal_2023_1.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/normals/ features tensor is: (2161, 28)\n",
      "Extracting features from ../dataset/extrastoles/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c4584860b0b4e859b4e2dacad37e174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles/ features tensor is: (806, 28)\n",
      "Features extracted and saved\n"
     ]
    }
   ],
   "source": [
    "# FEATURES EXTRACTION\n",
    "names = ['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles']\n",
    "features_dict = {}\n",
    "window_length = 1\n",
    "sample_rate = 'mix'\n",
    "n_mfcc = 40\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "# Save the features to a file\n",
    "storing_name = f'full_data_{window_length}_{sample_rate}_{n_mfcc}'  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "\n",
    "if os.path.exists(FEATURES_RAW_DIR + storing_name + '.npy'):\n",
    "     print('The features have already been extracted')\n",
    "     \n",
    "else:\n",
    "     for i, PATH_ in enumerate(PATHS):\n",
    "          \n",
    "          print(f'Extracting features from {PATH_}')\n",
    "          features = extract_features(PATH_, label = i, frame_length = window_length, n_mfcc=n_mfcc)\n",
    "          \n",
    "          # Stack the features into a single tensor\n",
    "          features = torch.cat(features, dim=0).numpy()\n",
    "          print(f'The shape of the {PATH_} features tensor is: {features.shape}')\n",
    "          \n",
    "          X = features[:,:-2]\n",
    "          y = features[:,-2]\n",
    "          filename = features[:,-1]\n",
    "          \n",
    "          local_dict = {'X': X, 'y': y, 'filename': filename}\n",
    "          \n",
    "          features_dict[names[i]] = local_dict\n",
    "               \n",
    "     # Save the features to a file\n",
    "     np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "               \n",
    "     print('Features extracted and saved')\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the artifacts features tensor is: (1199, 26)\n",
      "The shape of the artifacts labels tensor is: (1199,)\n",
      "The shape of the artifacts filenames tensor is: (1199,)\n",
      "-----------------------------------------------\n",
      "The shape of the extrahls features tensor is: (883, 26)\n",
      "The shape of the extrahls labels tensor is: (883,)\n",
      "The shape of the extrahls filenames tensor is: (883,)\n",
      "-----------------------------------------------\n",
      "The shape of the murmurs features tensor is: (1149, 26)\n",
      "The shape of the murmurs labels tensor is: (1149,)\n",
      "The shape of the murmurs filenames tensor is: (1149,)\n",
      "-----------------------------------------------\n",
      "The shape of the normals features tensor is: (2161, 26)\n",
      "The shape of the normals labels tensor is: (2161,)\n",
      "The shape of the normals filenames tensor is: (2161,)\n",
      "-----------------------------------------------\n",
      "The shape of the extrastoles features tensor is: (806, 26)\n",
      "The shape of the extrastoles labels tensor is: (806,)\n",
      "The shape of the extrastoles filenames tensor is: (806,)\n",
      "-----------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# load the features and check the shape\n",
    "features_dict = np.load(FEATURES_RAW_DIR + storing_name + '.npy', allow_pickle=True).item()\n",
    "for key in features_dict.keys():\n",
    "\tprint(f'The shape of the {key} features tensor is: {features_dict[key][\"X\"].shape}')\n",
    "\tprint(f'The shape of the {key} labels tensor is: {features_dict[key][\"y\"].shape}')\n",
    "\tprint(f'The shape of the {key} filenames tensor is: {features_dict[key][\"filename\"].shape}')\n",
    "\tprint('-----------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6198"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 0\n",
    "for key in features_dict.keys():\n",
    "\ts += features_dict[key][\"X\"].shape[0]\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
