{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction Notebook\n",
    "\n",
    "---\n",
    "\n",
    "This notebook is used to extract features from the data. The audio is divided into windows of 1 second. The features extracted from each audio window are:\n",
    "\n",
    "- **MFCC (Mel-Frequency Cepstral Coefficients)**: n_mfcc chosen by the user\n",
    "- **Chroma STFT**: 12 coefficients\n",
    "- **CQT (Constant-Q Transform)**: n_cqt chosen by the user\n",
    "- **RMS (Root Mean Square) Energy**: 1 coefficient\n",
    "- **Spectral Centroid**: 1 coefficient\n",
    "- **Spectral Bandwidth**: 1 coefficient\n",
    "- **Spectral Roll-off**: 1 coefficient\n",
    "- **Zero Crossing Rate**: 1 coefficient\n",
    "\n",
    "#### Sections:\n",
    "\n",
    "- [Feature Extraction](#Feature-Extraction)\n",
    "  - [Specific Features Extraction](#Specific-Features-Extraction)\n",
    "  - [All Features Extraction](#All-Features-Extraction)\n",
    "\n",
    "#### Findings:\n",
    "\n",
    "- We have highly unbalanced classes in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the functions\n",
    "import utils as utils\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import importlib\n",
    "import torchaudio\n",
    "import torch\n",
    "\n",
    "# import the utils module\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".cell-output-ipywidget-background {\n",
    "    background-color: transparent !important;\n",
    "}\n",
    ":root {\n",
    "    --jp-widgets-color: var(--vscode-editor-foreground);\n",
    "    --jp-widgets-font-size: var(--vscode-editor-font-size);\n",
    "}  \n",
    "</style>\n",
    "\n",
    "# -------- tqdm DARK THEME --------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Extraction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "#sr = 'mix'\n",
    "sr = 4000\n",
    "INTERVAL = 2\n",
    "\n",
    "# set the paths to data\n",
    "BASE_DIR = \"../dataset/\"\n",
    "ARTIFACTS_DIR = BASE_DIR + f\"artifacts_{sr}/\"\n",
    "EXTRAHLS_DIR = BASE_DIR + f\"extrahls_{sr}/\"\n",
    "MURMURS_DIR = BASE_DIR + f\"murmurs_{sr}/\"\n",
    "NORMALS_DIR = BASE_DIR + f\"normals_{sr}/\"\n",
    "EXTRASTOLES_DIR = BASE_DIR + f\"extrastoles_{sr}/\"\n",
    "\n",
    "# paths to save the features\n",
    "FEATURES_RAW_DIR = \"../features/raw/\"\n",
    "# FEATURES_RAW_DIR = \"../features/balanced/priori/\"\n",
    "\n",
    "PATHS = [ARTIFACTS_DIR, EXTRAHLS_DIR, MURMURS_DIR, NORMALS_DIR, EXTRASTOLES_DIR]\n",
    "\n",
    "# REMOVE THE AUGEMENTED SAMPLES WHEN EXTRACTING BASE RAW FEATURES\n",
    "# for path in PATHS:\n",
    "#      remove_generated_samples(path, 'USERAUGMENTED')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Features Extraction\n",
    "\n",
    "- **MFCC (Mel-Frequency Cepstral Coefficients)**: n_mfcc chosen by the user\n",
    "- **Chroma STFT**: 12 coefficients\n",
    "- **CQT (Constant-Q Transform)**: n_cqt chosen by the user\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(\n",
    "    dir_path: str,\n",
    "    label: str,\n",
    "    extraction_interval: float,\n",
    "    sample_rate: int = 44100,\n",
    "    n_mfcc: int = 13,\n",
    "    melkwargs: dict = {},\n",
    "    n_cqt: int = 84,\n",
    "    n_rms: int = 20,\n",
    "    n_zcr: int = 20,\n",
    "    n_sc: int = 20,\n",
    "    n_sb: int = 20, \n",
    "    n_sr: int = 20,\n",
    "    get_mfcc: bool = False,\n",
    "    get_chroma: bool = False,\n",
    "    get_cqt: bool = False,\n",
    "    get_rms: bool = False,\n",
    "    get_zcr: bool = False,\n",
    "    get_sc: bool = False,\n",
    "    get_sb: bool = False,\n",
    "    get_sr: bool = False,\n",
    ") -> list:\n",
    "    \"\"\"\n",
    "    Extracts audio features (MFCC, chroma, RMS, spectral centroid, spectral bandwidth, spectral rolloff, zero-crossing rate)\n",
    "    from audio files in the specified directory.\n",
    "\n",
    "    Args:\n",
    "        dir_path (str): The path to the directory containing audio files.\n",
    "        label (str): The label associated with the extracted features.\n",
    "        extraction_interval: The frame length for feature extraction.\n",
    "        sample_rate (int, optional): The sample rate of the audio files. Defaults to 44100 Hz.\n",
    "        n_mfcc (int, optional): The number of Mel-frequency cepstral coefficients (MFCCs) to extract. Defaults to 13.\n",
    "        melkwargs (dict, optional): Additional arguments for Mel spectrogram computation.\n",
    "        n_cqt (int, optional): The number of constant-Q transform (CQT) bins to extract. Defaults to 84.\n",
    "        n_rms (int, optional): The number of RMS values to extract. Defaults to 20.\n",
    "        n_zcr (int, optional): The number of zero-crossing rate values to extract. Defaults to 20.\n",
    "        n_sc (int, optional): The number of spectral centroid values to extract. Defaults to 20.\n",
    "        n_sb (int, optional): The number of spectral bandwidth values to extract. Defaults to 20.\n",
    "        n_sr (int, optional): The number of spectral rolloff values to extract. Defaults to 20.\n",
    "        get_mfcc (bool, optional): Whether to extract MFCC features. Defaults to False.\n",
    "        get_chroma (bool, optional): Whether to extract chroma features. Defaults to False.\n",
    "        get_cqt (bool, optional): Whether to extract CQT features. Defaults to False.\n",
    "        get_rms (bool, optional): Whether to extract RMS features. Defaults to False.\n",
    "        get_zcr (bool, optional): Whether to extract zero-crossing rate features. Defaults to False.\n",
    "        get_sc (bool, optional): Whether to extract spectral centroid features. Defaults to False.\n",
    "        get_sb (bool, optional): Whether to extract spectral bandwidth features. Defaults to False.\n",
    "        get_sr (bool, optional): Whether to extract spectral rolloff features. Defaults to False.\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "        list: A list containing tensors of extracted features for each audio file.\n",
    "    \"\"\"\n",
    "    filenames = os.listdir(dir_path)\n",
    "    filenames = [file for file in filenames if not file.startswith(\".\")]\n",
    "    extraction_interval = 1 / extraction_interval\n",
    "\n",
    "    features = []  # List to store the features for all files\n",
    "\n",
    "    for file in tqdm(filenames, desc=f\"Extraction in progress\"):\n",
    "        audio, orig_sample_rate = torchaudio.load(os.path.join(dir_path, file))\n",
    "        orig_sample_rate_tmp = int(orig_sample_rate / extraction_interval)\n",
    "        audio_length = int(max(audio[0].shape) / (orig_sample_rate_tmp))\n",
    "\n",
    "        sample_rate = orig_sample_rate\n",
    "\n",
    "        # Reduce the audio from stereo to mono if needed\n",
    "        if audio.shape[0] > 1:\n",
    "            print(f\"Converting stereo audio to mono for {file}...\")\n",
    "            audio = torch.mean(audio, dim=0).reshape(1, -1)\n",
    "\n",
    "        features_local = []  # List to store the MFCC features for each file\n",
    "\n",
    "        for i in range(audio_length):\n",
    "            # Lazy load the audio, one sec at a time, to avoid memory issues\n",
    "            audio_mono = utils.slicing(\n",
    "                audio,\n",
    "                offset=int(sample_rate / extraction_interval * i),\n",
    "                num_frames=int(sample_rate / extraction_interval * (i + 1)),\n",
    "            )\n",
    "\n",
    "            # Get the MFCC features\n",
    "            if get_mfcc:\n",
    "                mfcc_features_tmp = utils.extract_mfcc(\n",
    "                    audio_mono, sample_rate, n_mfcc, melkwargs\n",
    "                )\n",
    "            if get_chroma:\n",
    "                chroma_stft = utils.extract_chroma_stft(audio_mono, sample_rate)\n",
    "            if get_cqt:\n",
    "                cqt = utils.extract_cqt(\n",
    "                    audio_mono, sample_rate=sample_rate, n_cqt=n_cqt\n",
    "                )\n",
    "            if get_rms:\n",
    "                rms = extract_rms(audio_mono, num_values=n_rms)\n",
    "            if get_zcr:\n",
    "                zcr = extract_zero_crossing_rate(audio_mono, num_values=n_zcr)\n",
    "            if get_sc:\n",
    "                spec_cent = extract_spectral_centroid(audio_mono, sample_rate, num_values=n_sc)\n",
    "            if get_sb:\n",
    "                spec_bw = extract_spectral_bandwidth(audio_mono, sample_rate, num_values=n_sb)\n",
    "            if get_sr:\n",
    "                rolloff = extract_spectral_rolloff(audio_mono, sample_rate, num_values=n_sr)\n",
    "\n",
    "            #   spec_cent = extract_spectral_centroid(audio_mono, sample_rate)\n",
    "            #   spec_bw = extract_spectral_bandwidth(audio_mono, sample_rate)\n",
    "            #   rolloff = extract_spectral_rolloff(audio_mono, sample_rate)\n",
    "            #   zcr = extract_zero_crossing_rate(audio_mono)\n",
    "\n",
    "            # check that no more than one feature is extracted. Else raise an error\n",
    "            if sum([get_mfcc, get_chroma, get_cqt, get_rms, get_zcr, get_sc, get_sb, get_sr]) != 1:\n",
    "                raise ValueError(\n",
    "                    \"Exactly one feature must be extracted at a time. Please check the arguments.\"\n",
    "                )\n",
    "            \n",
    "            # Concatenate the features\n",
    "            if get_mfcc:\n",
    "                features_tmp = mfcc_features_tmp\n",
    "            if get_chroma:\n",
    "                features_tmp = chroma_stft\n",
    "            if get_cqt:\n",
    "                features_tmp = cqt\n",
    "            if get_rms:\n",
    "                features_tmp = rms\n",
    "            if get_zcr:\n",
    "                features_tmp = zcr\n",
    "            if get_sc:\n",
    "                features_tmp = spec_cent\n",
    "            if get_sb:\n",
    "                features_tmp = spec_bw\n",
    "            if get_sr:\n",
    "                features_tmp = rolloff\n",
    "            \n",
    "\n",
    "            features_local.append(features_tmp)\n",
    "\n",
    "        # If features_local is empty, skip the file\n",
    "        if features_local == []:\n",
    "            print(f\"No features extracted for {file}. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Stack the MFCC features into a single tensor\n",
    "        features_local = torch.stack(features_local, dim=0)\n",
    "\n",
    "        # Attach the label in the last column\n",
    "        features_local = torch.cat(\n",
    "            (features_local, torch.ones(features_local.shape[0], 1) * label), dim=1\n",
    "        )\n",
    "\n",
    "        # Attach the filename index in the last column\n",
    "        features_local = torch.cat(\n",
    "            (\n",
    "                features_local,\n",
    "                torch.full((features_local.shape[0], 1), filenames.index(file)),\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        features.append(features_local)\n",
    "\n",
    "    print(\"Finished processing all files.\\n\")\n",
    "    return features\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def extract_rms(audio: torch.Tensor, num_values: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract RMS features from an audio file.\n",
    "\n",
    "    Args:\n",
    "    - audio (torch.Tensor): The audio file.\n",
    "    - num_values (int): The number of RMS values to extract.\n",
    "\n",
    "    Returns:\n",
    "    - rms (torch.Tensor): The RMS features of the audio file.\n",
    "    \"\"\"\n",
    "    \n",
    "    num_samples = audio.shape[1]\n",
    "    hop_length = num_samples // num_values\n",
    "\n",
    "    \n",
    "    rms = librosa.feature.rms(y=audio.numpy(), frame_length=hop_length*2, hop_length=hop_length, center=True)\n",
    "    rms = torch.tensor(rms)\n",
    "    return rms.reshape(-1)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def extract_zero_crossing_rate(audio: torch.Tensor, num_values: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract Zero Crossing Rate features from an audio file.\n",
    "\n",
    "    Args:\n",
    "    - audio (torch.Tensor): The audio file.\n",
    "    - num_values (int): The number of Zero Crossing Rate values to extract.\n",
    "\n",
    "    Returns:\n",
    "    - zcr (torch.Tensor): The Zero Crossing Rate features of the audio file.\n",
    "    \"\"\"\n",
    "    num_samples = audio.shape[1]\n",
    "    hop_length = num_samples // num_values\n",
    "    \n",
    "    zcr = librosa.feature.zero_crossing_rate(y=audio.numpy(), frame_length=hop_length*2, hop_length=hop_length)\n",
    "    zcr = torch.tensor(zcr)\n",
    "    return zcr.reshape(-1)\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "def extract_spectral_centroid(audio: torch.Tensor, sample_rate: int, num_values: int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract Spectral Centroid features from an audio file.\n",
    "\n",
    "    Args:\n",
    "    - audio (torch.Tensor): The audio file.\n",
    "    - sample_rate (int): The sample rate of the audio file.\n",
    "    - num_values (int): The number of Spectral Centroid values to extract.\n",
    "\n",
    "    Returns:\n",
    "    - spec_cent (torch.Tensor): The Spectral Centroid features of the audio file.\n",
    "    \"\"\"\n",
    "    num_samples = audio.shape[1]\n",
    "    hop_length = num_samples // num_values\n",
    "    \n",
    "    sb = librosa.feature.spectral_centroid(y=audio.numpy(), n_fft=hop_length*2, hop_length=hop_length, sr=sample_rate)\n",
    "    sb = torch.tensor(sb)\n",
    "    return sb.reshape(-1)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def extract_spectral_bandwidth(audio: torch.Tensor, sample_rate: int, num_values:int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract Spectral Bandwidth features from an audio file.\n",
    "\n",
    "    Args:\n",
    "    - audio (torch.Tensor): The audio file.\n",
    "    - sample_rate (int): The sample rate of the audio file.\n",
    "    - num_values (int): The number of Spectral Bandwidth values to extract.\n",
    "\n",
    "    Returns:\n",
    "    - spec_bw (torch.Tensor): The Spectral Bandwidth features of the audio file.\n",
    "    \"\"\"\n",
    "    num_samples = audio.shape[1]\n",
    "    hop_length = num_samples // num_values\n",
    "    \n",
    "    sc = librosa.feature.spectral_bandwidth(y=audio.numpy(), n_fft=hop_length*2, hop_length=hop_length, sr=sample_rate)\n",
    "    sc = torch.tensor(sc)\n",
    "    return sc.reshape(-1)\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def extract_spectral_rolloff(audio: torch.Tensor, sample_rate: int, num_values:int) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Extract Spectral Rolloff features from an audio file.\n",
    "\n",
    "    Args:\n",
    "    - audio (torch.Tensor): The audio file.\n",
    "    - sample_rate (int): The sample rate of the audio file.\n",
    "    - num_values (int): The number of Spectral Rolloff values to extract.\n",
    "\n",
    "    Returns:\n",
    "    - rolloff (torch.Tensor): The Spectral Rolloff features of the audio file.\n",
    "    \"\"\"\n",
    "    num_samples = audio.shape[1]\n",
    "    hop_length = num_samples // num_values\n",
    "    \n",
    "    sr = librosa.feature.spectral_rolloff(y=audio.numpy(), n_fft=hop_length*2, hop_length=hop_length, sr=sample_rate)\n",
    "    sr = torch.tensor(sr)\n",
    "    return sr.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- MFCC -------------------------\n",
    "n_mfcc_list = [30, 60, 90, 120]\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"mfcc\"  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for n_mfcc in n_mfcc_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_mfcc}{type_}\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_mfcc=n_mfcc,\n",
    "                get_mfcc=True,\n",
    "                get_chroma=False,\n",
    "                get_cqt=False,\n",
    "            )\n",
    "\n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- CHROMA -------------------------\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "n_features = 12\n",
    "type_ = \"chroma\"  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for n_mfcc in n_mfcc_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_features}{type_}\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_mfcc=n_mfcc,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=True,\n",
    "                get_cqt=False,\n",
    "            )\n",
    "\n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- CQT -------------------------\n",
    "n_cqt_list = [\n",
    "    20,\n",
    "    30,\n",
    "    40,\n",
    "    60,\n",
    "    70,\n",
    "]\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"cqt\"  # mfcc, mel_spec, spec, cqt\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "for n_cqt in n_cqt_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_cqt}{type_}\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_cqt=n_cqt,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=False,\n",
    "                get_cqt=True,\n",
    "            )\n",
    "\n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- RMS -------------------------\n",
    "n_rms_list = [\n",
    "    20,\n",
    "    40,\n",
    "    60,\n",
    "]\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"rms\"  # mfcc, mel_spec, spec, cqt, rms\n",
    "\n",
    "for n_rms in n_rms_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_rms}{type_}\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_rms=n_rms,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=False,\n",
    "                get_cqt=False,\n",
    "                get_rms=True,\n",
    "            )\n",
    "\n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- ZCR -------------------------\n",
    "n_zcr_list = [\n",
    "    20,\n",
    "    40,\n",
    "    60,\n",
    "]\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"zcr\"  # mfcc, mel_spec, spec, cqt, rms\n",
    "\n",
    "for n_zcr in n_zcr_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_zcr+1}{type_}\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_zcr=n_zcr,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=False,\n",
    "                get_cqt=False,\n",
    "                get_rms=False,\n",
    "                get_zcr=True,\n",
    "            )\n",
    "\n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- SPECTRAL CENTROID -------------------------\n",
    "n_sc_list = [\n",
    "    20,\n",
    "    40,\n",
    "    60,\n",
    "]\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"sc\"  # mfcc, mel_spec, spec, cqt, rms\n",
    "\n",
    "for n_sc in n_sc_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_sc+1}{type_}\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_sc=n_sc,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=False,\n",
    "                get_cqt=False,\n",
    "                get_rms=False,\n",
    "                get_zcr=False,\n",
    "                get_sc=True,\n",
    "            )\n",
    "\n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- SPECTRAL BANDWIDTH -------------------------\n",
    "n_sb_list = [\n",
    "    20,\n",
    "    40,\n",
    "    60,\n",
    "]\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"sb\"  # mfcc, mel_spec, spec, cqt, rms\n",
    "\n",
    "for n_sb in n_sb_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_sb+1}{type_}\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_sb=n_sb,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=False,\n",
    "                get_cqt=False,\n",
    "                get_rms=False,\n",
    "                get_zcr=False,\n",
    "                get_sc=False,\n",
    "                get_sb = True\n",
    "            )\n",
    "\n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting features from ../dataset/artifacts_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c608a5e2a0994a8ca608ec28aadac42c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_17.wav...\n",
      "Converting stereo audio to mono for artifact_2023_16.wav...\n",
      "Converting stereo audio to mono for artifact_2023_14.wav...\n",
      "Converting stereo audio to mono for artifact_2023_15.wav...\n",
      "Converting stereo audio to mono for artifact_2023_39.wav...\n",
      "Converting stereo audio to mono for artifact_2023_11.wav...\n",
      "Converting stereo audio to mono for artifact_2023_38.wav...\n",
      "Converting stereo audio to mono for artifact_2023_12.wav...\n",
      "Converting stereo audio to mono for artifact_2023_13.wav...\n",
      "Converting stereo audio to mono for artifact_2023_49.wav...\n",
      "Converting stereo audio to mono for artifact_2023_41.wav...\n",
      "Converting stereo audio to mono for artifact_2023_40.wav...\n",
      "Converting stereo audio to mono for artifact_2023_42.wav...\n",
      "Converting stereo audio to mono for artifact_2023_43.wav...\n",
      "Converting stereo audio to mono for artifact_2023_47.wav...\n",
      "Converting stereo audio to mono for artifact_2023_46.wav...\n",
      "Converting stereo audio to mono for artifact_2023_50.wav...\n",
      "Converting stereo audio to mono for artifact_2023_44.wav...\n",
      "Converting stereo audio to mono for artifact_2023_45.wav...\n",
      "Converting stereo audio to mono for artifact_2023_51.wav...\n",
      "Converting stereo audio to mono for artifact_2023_36.wav...\n",
      "Converting stereo audio to mono for artifact_2023_22.wav...\n",
      "Converting stereo audio to mono for artifact_2023_4.wav...\n",
      "Converting stereo audio to mono for artifact_2023_5.wav...\n",
      "Converting stereo audio to mono for artifact_2023_23.wav...\n",
      "Converting stereo audio to mono for artifact_2023_37.wav...\n",
      "Converting stereo audio to mono for artifact_2023_21.wav...\n",
      "Converting stereo audio to mono for artifact_2023_35.wav...\n",
      "Converting stereo audio to mono for artifact_2023_7.wav...\n",
      "Converting stereo audio to mono for artifact_2023_6.wav...\n",
      "Converting stereo audio to mono for artifact_2023_34.wav...\n",
      "Converting stereo audio to mono for artifact_2023_20.wav...\n",
      "Converting stereo audio to mono for artifact_2023_18.wav...\n",
      "Converting stereo audio to mono for artifact_2023_24.wav...\n",
      "Converting stereo audio to mono for artifact_2023_2.wav...\n",
      "Converting stereo audio to mono for artifact_2023_25.wav...\n",
      "Converting stereo audio to mono for artifact_2023_19.wav...\n",
      "Converting stereo audio to mono for artifact_2023_33.wav...\n",
      "Converting stereo audio to mono for artifact_2023_1.wav...\n",
      "Converting stereo audio to mono for artifact_2023_0.wav...\n",
      "Converting stereo audio to mono for artifact_2023_26.wav...\n",
      "Converting stereo audio to mono for artifact_2023_32.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/artifacts_4000/ features tensor is: (970, 23)\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "528d0f2b2fd142cdbfdf96552ecfda5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for extrahls__201104140118.wav. Skipping...\n",
      "No features extracted for extrahls__201104270459.wav. Skipping...\n",
      "No features extracted for extrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (55, 23)\n",
      "Extracting features from ../dataset/murmurs_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9fc41981de4f368620d97489dacc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for murmur__293_1311680805936_B1.wav. Skipping...\n",
      "No features extracted for murmur__201104021355.wav. Skipping...\n",
      "Converting stereo audio to mono for abnormal_s4_2023_2.wav...\n",
      "No features extracted for murmur__171_1307971016233_E.wav. Skipping...\n",
      "Converting stereo audio to mono for atrial_septal_defect_2023_6.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_1.wav...\n",
      "Converting stereo audio to mono for mitral_stenosis_2023_9.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_0.wav...\n",
      "No features extracted for murmur_noisymurmur_171_1307971016233_D.wav. Skipping...\n",
      "Converting stereo audio to mono for holosystolic_murmur_2023_7.wav...\n",
      "Converting stereo audio to mono for aortic_stenosis_2023_4.wav...\n",
      "Converting stereo audio to mono for mitral_valve_prolapse_2023_10.wav...\n",
      "Converting stereo audio to mono for innocent_murmur_2023_8.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/murmurs_4000/ features tensor is: (534, 23)\n",
      "Extracting features from ../dataset/normals_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dfd97a4fa87444d864abda8c8db9d04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for normal__232_1308748524018_D1.wav. Skipping...\n",
      "No features extracted for normal__210_1308162935880_D2.wav. Skipping...\n",
      "No features extracted for normal__210_1308162935880_D1.wav. Skipping...\n",
      "No features extracted for normal__143_1306763822290_C.wav. Skipping...\n",
      "No features extracted for normal__147_1306523973811_C.wav. Skipping...\n",
      "No features extracted for normal__238_1309194586293_B.wav. Skipping...\n",
      "No features extracted for normal__190_1308076920011_C1.wav. Skipping...\n",
      "No features extracted for normal__230_1308595300880_B.wav. Skipping...\n",
      "No features extracted for normal__267_1309368735165_A.wav. Skipping...\n",
      "No features extracted for normal__238_1309194586293_A.wav. Skipping...\n",
      "No features extracted for normal__286_1311170606028_A1.wav. Skipping...\n",
      "No features extracted for normal__210_1308162935880_B1.wav. Skipping...\n",
      "No features extracted for normal__252_1309203336604_B.wav. Skipping...\n",
      "No features extracted for normal__134_1306428161797_C2.wav. Skipping...\n",
      "No features extracted for normal__201_1308144942432_A.wav. Skipping...\n",
      "No features extracted for normal__175_1307987962616_B1.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_137_1306764999211_C1.wav. Skipping...\n",
      "No features extracted for normal__232_1308748524018_B1.wav. Skipping...\n",
      "No features extracted for normal__235_1308749032454_C.wav. Skipping...\n",
      "No features extracted for normal__296_1311682952647_A1.wav. Skipping...\n",
      "No features extracted for normal__250_1309202496494_A.wav. Skipping...\n",
      "No features extracted for normal__296_1311682952647_A2.wav. Skipping...\n",
      "No features extracted for normal__286_1311170606028_A.wav. Skipping...\n",
      "No features extracted for normal__146_1306778707532_D3.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_173_1307973611151_B.wav. Skipping...\n",
      "No features extracted for normal__232_1308748524018_A.wav. Skipping...\n",
      "No features extracted for normal__209_1308162216750_A1.wav. Skipping...\n",
      "No features extracted for normal__159_1307018640315_B2.wav. Skipping...\n",
      "No features extracted for normal__154_1306935608852_D.wav. Skipping...\n",
      "No features extracted for normal__152_1306779561195_C1.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_178_1307989887769_B1.wav. Skipping...\n",
      "No features extracted for normal__295_1311682673157_D.wav. Skipping...\n",
      "No features extracted for normal__232_1308748524018_B.wav. Skipping...\n",
      "No features extracted for normal__210_1308162935880_B.wav. Skipping...\n",
      "No features extracted for normal__232_1308748524018_C.wav. Skipping...\n",
      "No features extracted for normal__158_1306947254705_B2.wav. Skipping...\n",
      "No features extracted for normal__282_1311166081161_C.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_137_1306764999211_B.wav. Skipping...\n",
      "No features extracted for normal__283_1311167409239_A.wav. Skipping...\n",
      "No features extracted for normal__274_1311075637574_D.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_234_1308748855534_B.wav. Skipping...\n",
      "No features extracted for normal__134_1306428161797_D.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_3.wav...\n",
      "No features extracted for normal__237_1308750231222_C.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_2.wav...\n",
      "No features extracted for normal__133_1306759619127_D.wav. Skipping...\n",
      "No features extracted for normal__274_1311075637574_B1.wav. Skipping...\n",
      "No features extracted for normal__176_1307988171173_B1.wav. Skipping...\n",
      "No features extracted for normal__215_1308245664733_C1.wav. Skipping...\n",
      "No features extracted for normal__218_1308246311449_C.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_0.wav...\n",
      "Converting stereo audio to mono for normal_2023_1.wav...\n",
      "No features extracted for normal__214_1308245489717_A.wav. Skipping...\n",
      "No features extracted for normal__167_1307111318050_C.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/normals_4000/ features tensor is: (984, 23)\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8ca59415334e89a9aa61957b335e1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for extrastole__190_1308076920011_C.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (113, 23)\n",
      "Features extracted and saved\n",
      "Extracting features from ../dataset/artifacts_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1689d5c586c4388a7a0a303976ccac8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_17.wav...\n",
      "Converting stereo audio to mono for artifact_2023_16.wav...\n",
      "Converting stereo audio to mono for artifact_2023_14.wav...\n",
      "Converting stereo audio to mono for artifact_2023_15.wav...\n",
      "Converting stereo audio to mono for artifact_2023_39.wav...\n",
      "Converting stereo audio to mono for artifact_2023_11.wav...\n",
      "Converting stereo audio to mono for artifact_2023_38.wav...\n",
      "Converting stereo audio to mono for artifact_2023_12.wav...\n",
      "Converting stereo audio to mono for artifact_2023_13.wav...\n",
      "Converting stereo audio to mono for artifact_2023_49.wav...\n",
      "Converting stereo audio to mono for artifact_2023_41.wav...\n",
      "Converting stereo audio to mono for artifact_2023_40.wav...\n",
      "Converting stereo audio to mono for artifact_2023_42.wav...\n",
      "Converting stereo audio to mono for artifact_2023_43.wav...\n",
      "Converting stereo audio to mono for artifact_2023_47.wav...\n",
      "Converting stereo audio to mono for artifact_2023_46.wav...\n",
      "Converting stereo audio to mono for artifact_2023_50.wav...\n",
      "Converting stereo audio to mono for artifact_2023_44.wav...\n",
      "Converting stereo audio to mono for artifact_2023_45.wav...\n",
      "Converting stereo audio to mono for artifact_2023_51.wav...\n",
      "Converting stereo audio to mono for artifact_2023_36.wav...\n",
      "Converting stereo audio to mono for artifact_2023_22.wav...\n",
      "Converting stereo audio to mono for artifact_2023_4.wav...\n",
      "Converting stereo audio to mono for artifact_2023_5.wav...\n",
      "Converting stereo audio to mono for artifact_2023_23.wav...\n",
      "Converting stereo audio to mono for artifact_2023_37.wav...\n",
      "Converting stereo audio to mono for artifact_2023_21.wav...\n",
      "Converting stereo audio to mono for artifact_2023_35.wav...\n",
      "Converting stereo audio to mono for artifact_2023_7.wav...\n",
      "Converting stereo audio to mono for artifact_2023_6.wav...\n",
      "Converting stereo audio to mono for artifact_2023_34.wav...\n",
      "Converting stereo audio to mono for artifact_2023_20.wav...\n",
      "Converting stereo audio to mono for artifact_2023_18.wav...\n",
      "Converting stereo audio to mono for artifact_2023_24.wav...\n",
      "Converting stereo audio to mono for artifact_2023_2.wav...\n",
      "Converting stereo audio to mono for artifact_2023_25.wav...\n",
      "Converting stereo audio to mono for artifact_2023_19.wav...\n",
      "Converting stereo audio to mono for artifact_2023_33.wav...\n",
      "Converting stereo audio to mono for artifact_2023_1.wav...\n",
      "Converting stereo audio to mono for artifact_2023_0.wav...\n",
      "Converting stereo audio to mono for artifact_2023_26.wav...\n",
      "Converting stereo audio to mono for artifact_2023_32.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/artifacts_4000/ features tensor is: (970, 43)\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2235d75208e447c082f6b9cc0a120515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for extrahls__201104140118.wav. Skipping...\n",
      "No features extracted for extrahls__201104270459.wav. Skipping...\n",
      "No features extracted for extrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (55, 43)\n",
      "Extracting features from ../dataset/murmurs_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c1097ec4d9466daa4221caa44d7c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for murmur__293_1311680805936_B1.wav. Skipping...\n",
      "No features extracted for murmur__201104021355.wav. Skipping...\n",
      "Converting stereo audio to mono for abnormal_s4_2023_2.wav...\n",
      "No features extracted for murmur__171_1307971016233_E.wav. Skipping...\n",
      "Converting stereo audio to mono for atrial_septal_defect_2023_6.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_1.wav...\n",
      "Converting stereo audio to mono for mitral_stenosis_2023_9.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_0.wav...\n",
      "No features extracted for murmur_noisymurmur_171_1307971016233_D.wav. Skipping...\n",
      "Converting stereo audio to mono for holosystolic_murmur_2023_7.wav...\n",
      "Converting stereo audio to mono for aortic_stenosis_2023_4.wav...\n",
      "Converting stereo audio to mono for mitral_valve_prolapse_2023_10.wav...\n",
      "Converting stereo audio to mono for innocent_murmur_2023_8.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/murmurs_4000/ features tensor is: (534, 43)\n",
      "Extracting features from ../dataset/normals_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f45a9098524d139601525633c5c260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for normal__232_1308748524018_D1.wav. Skipping...\n",
      "No features extracted for normal__210_1308162935880_D2.wav. Skipping...\n",
      "No features extracted for normal__210_1308162935880_D1.wav. Skipping...\n",
      "No features extracted for normal__143_1306763822290_C.wav. Skipping...\n",
      "No features extracted for normal__147_1306523973811_C.wav. Skipping...\n",
      "No features extracted for normal__238_1309194586293_B.wav. Skipping...\n",
      "No features extracted for normal__190_1308076920011_C1.wav. Skipping...\n",
      "No features extracted for normal__230_1308595300880_B.wav. Skipping...\n",
      "No features extracted for normal__267_1309368735165_A.wav. Skipping...\n",
      "No features extracted for normal__238_1309194586293_A.wav. Skipping...\n",
      "No features extracted for normal__286_1311170606028_A1.wav. Skipping...\n",
      "No features extracted for normal__210_1308162935880_B1.wav. Skipping...\n",
      "No features extracted for normal__252_1309203336604_B.wav. Skipping...\n",
      "No features extracted for normal__134_1306428161797_C2.wav. Skipping...\n",
      "No features extracted for normal__201_1308144942432_A.wav. Skipping...\n",
      "No features extracted for normal__175_1307987962616_B1.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_137_1306764999211_C1.wav. Skipping...\n",
      "No features extracted for normal__232_1308748524018_B1.wav. Skipping...\n",
      "No features extracted for normal__235_1308749032454_C.wav. Skipping...\n",
      "No features extracted for normal__296_1311682952647_A1.wav. Skipping...\n",
      "No features extracted for normal__250_1309202496494_A.wav. Skipping...\n",
      "No features extracted for normal__296_1311682952647_A2.wav. Skipping...\n",
      "No features extracted for normal__286_1311170606028_A.wav. Skipping...\n",
      "No features extracted for normal__146_1306778707532_D3.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_173_1307973611151_B.wav. Skipping...\n",
      "No features extracted for normal__232_1308748524018_A.wav. Skipping...\n",
      "No features extracted for normal__209_1308162216750_A1.wav. Skipping...\n",
      "No features extracted for normal__159_1307018640315_B2.wav. Skipping...\n",
      "No features extracted for normal__154_1306935608852_D.wav. Skipping...\n",
      "No features extracted for normal__152_1306779561195_C1.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_178_1307989887769_B1.wav. Skipping...\n",
      "No features extracted for normal__295_1311682673157_D.wav. Skipping...\n",
      "No features extracted for normal__232_1308748524018_B.wav. Skipping...\n",
      "No features extracted for normal__210_1308162935880_B.wav. Skipping...\n",
      "No features extracted for normal__232_1308748524018_C.wav. Skipping...\n",
      "No features extracted for normal__158_1306947254705_B2.wav. Skipping...\n",
      "No features extracted for normal__282_1311166081161_C.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_137_1306764999211_B.wav. Skipping...\n",
      "No features extracted for normal__283_1311167409239_A.wav. Skipping...\n",
      "No features extracted for normal__274_1311075637574_D.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_234_1308748855534_B.wav. Skipping...\n",
      "No features extracted for normal__134_1306428161797_D.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_3.wav...\n",
      "No features extracted for normal__237_1308750231222_C.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_2.wav...\n",
      "No features extracted for normal__133_1306759619127_D.wav. Skipping...\n",
      "No features extracted for normal__274_1311075637574_B1.wav. Skipping...\n",
      "No features extracted for normal__176_1307988171173_B1.wav. Skipping...\n",
      "No features extracted for normal__215_1308245664733_C1.wav. Skipping...\n",
      "No features extracted for normal__218_1308246311449_C.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_0.wav...\n",
      "Converting stereo audio to mono for normal_2023_1.wav...\n",
      "No features extracted for normal__214_1308245489717_A.wav. Skipping...\n",
      "No features extracted for normal__167_1307111318050_C.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/normals_4000/ features tensor is: (984, 43)\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e52aac85d6a40dca0fcd4a4b4c96575",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for extrastole__190_1308076920011_C.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (113, 43)\n",
      "Features extracted and saved\n",
      "Extracting features from ../dataset/artifacts_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc0d167c34541d1843160ddc7d889d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting stereo audio to mono for artifact_2023_17.wav...\n",
      "Converting stereo audio to mono for artifact_2023_16.wav...\n",
      "Converting stereo audio to mono for artifact_2023_14.wav...\n",
      "Converting stereo audio to mono for artifact_2023_15.wav...\n",
      "Converting stereo audio to mono for artifact_2023_39.wav...\n",
      "Converting stereo audio to mono for artifact_2023_11.wav...\n",
      "Converting stereo audio to mono for artifact_2023_38.wav...\n",
      "Converting stereo audio to mono for artifact_2023_12.wav...\n",
      "Converting stereo audio to mono for artifact_2023_13.wav...\n",
      "Converting stereo audio to mono for artifact_2023_49.wav...\n",
      "Converting stereo audio to mono for artifact_2023_41.wav...\n",
      "Converting stereo audio to mono for artifact_2023_40.wav...\n",
      "Converting stereo audio to mono for artifact_2023_42.wav...\n",
      "Converting stereo audio to mono for artifact_2023_43.wav...\n",
      "Converting stereo audio to mono for artifact_2023_47.wav...\n",
      "Converting stereo audio to mono for artifact_2023_46.wav...\n",
      "Converting stereo audio to mono for artifact_2023_50.wav...\n",
      "Converting stereo audio to mono for artifact_2023_44.wav...\n",
      "Converting stereo audio to mono for artifact_2023_45.wav...\n",
      "Converting stereo audio to mono for artifact_2023_51.wav...\n",
      "Converting stereo audio to mono for artifact_2023_36.wav...\n",
      "Converting stereo audio to mono for artifact_2023_22.wav...\n",
      "Converting stereo audio to mono for artifact_2023_4.wav...\n",
      "Converting stereo audio to mono for artifact_2023_5.wav...\n",
      "Converting stereo audio to mono for artifact_2023_23.wav...\n",
      "Converting stereo audio to mono for artifact_2023_37.wav...\n",
      "Converting stereo audio to mono for artifact_2023_21.wav...\n",
      "Converting stereo audio to mono for artifact_2023_35.wav...\n",
      "Converting stereo audio to mono for artifact_2023_7.wav...\n",
      "Converting stereo audio to mono for artifact_2023_6.wav...\n",
      "Converting stereo audio to mono for artifact_2023_34.wav...\n",
      "Converting stereo audio to mono for artifact_2023_20.wav...\n",
      "Converting stereo audio to mono for artifact_2023_18.wav...\n",
      "Converting stereo audio to mono for artifact_2023_24.wav...\n",
      "Converting stereo audio to mono for artifact_2023_2.wav...\n",
      "Converting stereo audio to mono for artifact_2023_25.wav...\n",
      "Converting stereo audio to mono for artifact_2023_19.wav...\n",
      "Converting stereo audio to mono for artifact_2023_33.wav...\n",
      "Converting stereo audio to mono for artifact_2023_1.wav...\n",
      "Converting stereo audio to mono for artifact_2023_0.wav...\n",
      "Converting stereo audio to mono for artifact_2023_26.wav...\n",
      "Converting stereo audio to mono for artifact_2023_32.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/artifacts_4000/ features tensor is: (970, 63)\n",
      "Extracting features from ../dataset/extrahls_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073d19dc7fe64bf198bfaf0aaad68c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for extrahls__201104140118.wav. Skipping...\n",
      "No features extracted for extrahls__201104270459.wav. Skipping...\n",
      "No features extracted for extrahls__201104021355.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrahls_4000/ features tensor is: (55, 63)\n",
      "Extracting features from ../dataset/murmurs_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "655d0143e52247e285c8a9470540bcef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for murmur__293_1311680805936_B1.wav. Skipping...\n",
      "No features extracted for murmur__201104021355.wav. Skipping...\n",
      "Converting stereo audio to mono for abnormal_s4_2023_2.wav...\n",
      "No features extracted for murmur__171_1307971016233_E.wav. Skipping...\n",
      "Converting stereo audio to mono for atrial_septal_defect_2023_6.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_1.wav...\n",
      "Converting stereo audio to mono for mitral_stenosis_2023_9.wav...\n",
      "Converting stereo audio to mono for abnormal_s3_2023_0.wav...\n",
      "No features extracted for murmur_noisymurmur_171_1307971016233_D.wav. Skipping...\n",
      "Converting stereo audio to mono for holosystolic_murmur_2023_7.wav...\n",
      "Converting stereo audio to mono for aortic_stenosis_2023_4.wav...\n",
      "Converting stereo audio to mono for mitral_valve_prolapse_2023_10.wav...\n",
      "Converting stereo audio to mono for innocent_murmur_2023_8.wav...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/murmurs_4000/ features tensor is: (534, 63)\n",
      "Extracting features from ../dataset/normals_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ec3704f37c4a7dbce3f9b8ebb95739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/355 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for normal__232_1308748524018_D1.wav. Skipping...\n",
      "No features extracted for normal__210_1308162935880_D2.wav. Skipping...\n",
      "No features extracted for normal__210_1308162935880_D1.wav. Skipping...\n",
      "No features extracted for normal__143_1306763822290_C.wav. Skipping...\n",
      "No features extracted for normal__147_1306523973811_C.wav. Skipping...\n",
      "No features extracted for normal__238_1309194586293_B.wav. Skipping...\n",
      "No features extracted for normal__190_1308076920011_C1.wav. Skipping...\n",
      "No features extracted for normal__230_1308595300880_B.wav. Skipping...\n",
      "No features extracted for normal__267_1309368735165_A.wav. Skipping...\n",
      "No features extracted for normal__238_1309194586293_A.wav. Skipping...\n",
      "No features extracted for normal__286_1311170606028_A1.wav. Skipping...\n",
      "No features extracted for normal__210_1308162935880_B1.wav. Skipping...\n",
      "No features extracted for normal__252_1309203336604_B.wav. Skipping...\n",
      "No features extracted for normal__134_1306428161797_C2.wav. Skipping...\n",
      "No features extracted for normal__201_1308144942432_A.wav. Skipping...\n",
      "No features extracted for normal__175_1307987962616_B1.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_137_1306764999211_C1.wav. Skipping...\n",
      "No features extracted for normal__232_1308748524018_B1.wav. Skipping...\n",
      "No features extracted for normal__235_1308749032454_C.wav. Skipping...\n",
      "No features extracted for normal__296_1311682952647_A1.wav. Skipping...\n",
      "No features extracted for normal__250_1309202496494_A.wav. Skipping...\n",
      "No features extracted for normal__296_1311682952647_A2.wav. Skipping...\n",
      "No features extracted for normal__286_1311170606028_A.wav. Skipping...\n",
      "No features extracted for normal__146_1306778707532_D3.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_173_1307973611151_B.wav. Skipping...\n",
      "No features extracted for normal__232_1308748524018_A.wav. Skipping...\n",
      "No features extracted for normal__209_1308162216750_A1.wav. Skipping...\n",
      "No features extracted for normal__159_1307018640315_B2.wav. Skipping...\n",
      "No features extracted for normal__154_1306935608852_D.wav. Skipping...\n",
      "No features extracted for normal__152_1306779561195_C1.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_178_1307989887769_B1.wav. Skipping...\n",
      "No features extracted for normal__295_1311682673157_D.wav. Skipping...\n",
      "No features extracted for normal__232_1308748524018_B.wav. Skipping...\n",
      "No features extracted for normal__210_1308162935880_B.wav. Skipping...\n",
      "No features extracted for normal__232_1308748524018_C.wav. Skipping...\n",
      "No features extracted for normal__158_1306947254705_B2.wav. Skipping...\n",
      "No features extracted for normal__282_1311166081161_C.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_137_1306764999211_B.wav. Skipping...\n",
      "No features extracted for normal__283_1311167409239_A.wav. Skipping...\n",
      "No features extracted for normal__274_1311075637574_D.wav. Skipping...\n",
      "No features extracted for normal_noisynormal_234_1308748855534_B.wav. Skipping...\n",
      "No features extracted for normal__134_1306428161797_D.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_3.wav...\n",
      "No features extracted for normal__237_1308750231222_C.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_2.wav...\n",
      "No features extracted for normal__133_1306759619127_D.wav. Skipping...\n",
      "No features extracted for normal__274_1311075637574_B1.wav. Skipping...\n",
      "No features extracted for normal__176_1307988171173_B1.wav. Skipping...\n",
      "No features extracted for normal__215_1308245664733_C1.wav. Skipping...\n",
      "No features extracted for normal__218_1308246311449_C.wav. Skipping...\n",
      "Converting stereo audio to mono for normal_2023_0.wav...\n",
      "Converting stereo audio to mono for normal_2023_1.wav...\n",
      "No features extracted for normal__214_1308245489717_A.wav. Skipping...\n",
      "No features extracted for normal__167_1307111318050_C.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/normals_4000/ features tensor is: (984, 63)\n",
      "Extracting features from ../dataset/extrastoles_4000/\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c5c59f61d24fbaae1015c2f44756e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction in progress:   0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No features extracted for extrastole__190_1308076920011_C.wav. Skipping...\n",
      "Finished processing all files.\n",
      "\n",
      "The shape of the ../dataset/extrastoles_4000/ features tensor is: (113, 63)\n",
      "Features extracted and saved\n"
     ]
    }
   ],
   "source": [
    "# ------------------------- SPECTRAL ROLLOFF -------------------------\n",
    "n_sr_list = [\n",
    "    20,\n",
    "    40,\n",
    "    60,\n",
    "]\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = INTERVAL\n",
    "type_ = \"sr\"  # mfcc, mel_spec, spec, cqt, rms\n",
    "\n",
    "for n_sr in n_sr_list:\n",
    "    # Save the features to a file\n",
    "    storing_name = f\"full_data_{interval}s_{sr}hz_{n_sr+1}{type_}\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "    if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "        print(\"The features have already been extracted\")\n",
    "\n",
    "    else:\n",
    "        for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "            print(f\"Extracting features from {PATH_}\")\n",
    "            features = extract_features(\n",
    "                PATH_,\n",
    "                label=i,\n",
    "                extraction_interval=interval,\n",
    "                n_sr=n_sr,\n",
    "                get_mfcc=False,\n",
    "                get_chroma=False,\n",
    "                get_cqt=False,\n",
    "                get_rms=False,\n",
    "                get_zcr=False,\n",
    "                get_sc=False,\n",
    "                get_sb = False,\n",
    "                get_sr=True,\n",
    "            )\n",
    "\n",
    "            # Stack the features into a single tensor\n",
    "            features = torch.cat(features, dim=0).numpy()\n",
    "            print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "            X = features[:, :-2]\n",
    "            y = features[:, -2]\n",
    "            filename = features[:, -1]\n",
    "\n",
    "            local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "            features_dict[names[i]] = local_dict\n",
    "\n",
    "        # Save the features to a file\n",
    "        np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "        print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Features Extraction\n",
    "\n",
    "- **MFCC (Mel-Frequency Cepstral Coefficients)**: n_mfcc chosen by the user\n",
    "- **Chroma STFT**: 12 coefficients\n",
    "- **CQT (Constant-Q Transform)**: n_cqt chosen by the user\n",
    "- **RMS (Root Mean Square) Energy**: 1 coefficient\n",
    "- **Spectral Centroid**: 1 coefficient\n",
    "- **Spectral Bandwidth**: 1 coefficient\n",
    "- **Spectral Roll-off**: 1 coefficient\n",
    "- **Zero Crossing Rate**: 1 coefficient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURES EXTRACTION\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "features_dict = {}\n",
    "interval = 1\n",
    "n_mfcc = 30  # 30, 120\n",
    "n_cqt = 70  # 30, 70\n",
    "\n",
    "# melkwargs = {'n_fft': 2048, 'hop_length': 512, 'n_mels': 128}\n",
    "\n",
    "# Save the features to a file\n",
    "storing_name = f\"full_data_{interval}s_{sr}hz_{n_mfcc}mfcc_{n_cqt}cqt_12chroma\"  ########## CHANGE THIS TO CHANGE THE NAME OF THE FILE\n",
    "\n",
    "\n",
    "if os.path.exists(FEATURES_RAW_DIR + storing_name + \".npy\"):\n",
    "    print(\"The features have already been extracted\")\n",
    "\n",
    "else:\n",
    "    for i, PATH_ in enumerate(PATHS):\n",
    "\n",
    "        print(f\"Extracting features from {PATH_}\")\n",
    "        features = utils.extract_features(\n",
    "            PATH_, label=i, frame_length=interval, n_mfcc=n_mfcc, n_cqt=n_cqt\n",
    "        )\n",
    "\n",
    "        # Stack the features into a single tensor\n",
    "        features = torch.cat(features, dim=0).numpy()\n",
    "        print(f\"The shape of the {PATH_} features tensor is: {features.shape}\")\n",
    "\n",
    "        X = features[:, :-2]\n",
    "        y = features[:, -2]\n",
    "        filename = features[:, -1]\n",
    "\n",
    "        local_dict = {\"X\": X, \"y\": y, \"filename\": filename}\n",
    "\n",
    "        features_dict[names[i]] = local_dict\n",
    "\n",
    "    # Save the features to a file\n",
    "    np.save(FEATURES_RAW_DIR + storing_name, features_dict)\n",
    "\n",
    "    print(\"Features extracted and saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features and check the shape\n",
    "features_dict = np.load(\n",
    "    FEATURES_RAW_DIR + storing_name + \".npy\", allow_pickle=True\n",
    ").item()\n",
    "for key in features_dict.keys():\n",
    "    print(f'The shape of the {key} features tensor is: {features_dict[key][\"X\"].shape}')\n",
    "    print(f'The shape of the {key} labels tensor is: {features_dict[key][\"y\"].shape}')\n",
    "    print(\n",
    "        f'The shape of the {key} filenames tensor is: {features_dict[key][\"filename\"].shape}'\n",
    "    )\n",
    "    print(\"-----------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "for key in features_dict.keys():\n",
    "    s += features_dict[key][\"X\"].shape[0]\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
