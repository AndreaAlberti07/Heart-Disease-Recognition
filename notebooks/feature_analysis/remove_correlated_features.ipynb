{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Engineering Notebook\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, we analyze the extracted features, assessing the necessity of normalization. We also investigate possible feature selection techniques to reduce the dimensionality of the data.\n",
    "The sections are organized as follows:\n",
    "\n",
    "1. [Load Data](#Load-Data)\n",
    "2. [Feature Analysis](#2.-Feature-Analysis)\n",
    "    1. [Visualize Features](#2.1.-Visualize-Features)\n",
    "    2. [Feature correlation](#2.2.-Feature-Correlation)\n",
    "3. [Covariance analysis](#3-covariance-matrix-of-the-groups)\n",
    "4. [Feature Selection](#4.-Feature-Selection)\n",
    "5. [Outliers Detection](#5.-Outliers-Detection)\n",
    "6. [Feature distribution](#6-Feature-Distribution)\n",
    "7. [PCA](#7-PCA)\n",
    "8. [Save the data](#8-Save-Data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the functions\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import pandas as pd\n",
    "from utils import remove_highly_correlated_features\n",
    "from scipy.stats import spearmanr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_not_correlated_with_target(\n",
    "    data_df: pd.DataFrame, threshold: float = 0.41\n",
    ") -> pd.Index:\n",
    "    # Importa le librerie necessarie\n",
    "    p_values = []\n",
    "    correlazione = []\n",
    "    features = []\n",
    "    # Calcola i coefficienti di correlazione di Kendall e i valori p per ogni coppia di colonne nel dataframe\n",
    "    for col1 in data_df.columns:\n",
    "        correlation, p_value = spearmanr(data_df[col1], data_df[\"label\"])\n",
    "        p_values.append(p_value)\n",
    "        correlazione.append(correlation)\n",
    "        features.append(col1)\n",
    "\n",
    "    correlazione_df = pd.DataFrame(\n",
    "        {\"Feature\": features, \"Correlazione\": correlazione, \"P-value\": p_values}\n",
    "    )\n",
    "    features_to_drop = correlazione_df[\n",
    "        np.abs(correlazione_df[\"Correlazione\"]) <= threshold\n",
    "    ].index\n",
    "\n",
    "    return features_to_drop\n",
    "\n",
    "\n",
    "def remove_features_highly_correlated(\n",
    "    data_df: pd.DataFrame, threshold: float = 0.7, max_corr_count: int = 2\n",
    ") -> pd.Index:\n",
    "    correlation_matrix = data_df.corr(method=\"spearman\")\n",
    "    correlation_matrix_no_target = data_df.drop(columns=[\"label\"]).corr(\n",
    "        method=\"spearman\"\n",
    "    )\n",
    "    features_to_drop = remove_highly_correlated_features(\n",
    "        correlation_matrix,\n",
    "        correlation_matrix_no_target,\n",
    "        threshold=threshold,\n",
    "        max_corr_count=max_corr_count,\n",
    "    )\n",
    "    return features_to_drop\n",
    "\n",
    "\n",
    "def get_samples(file_path: str, names: list):\n",
    "    dataset = []\n",
    "    if (\"posterior\" in file_path) or (\"both\" in file_path):\n",
    "        data = np.load(file_path, allow_pickle=True).item()\n",
    "        data = data[\"train_bal\"]\n",
    "        X = data[\"X\"]\n",
    "        y = data[\"y\"].reshape(-1, 1)\n",
    "        dataset = np.concatenate((X, y), axis=1)\n",
    "    else:\n",
    "        data_list = []\n",
    "        for name in names:\n",
    "            data = np.load(file_path, allow_pickle=True).item()\n",
    "            data = data[name]\n",
    "            X = data[\"X\"]\n",
    "            y = data[\"y\"].reshape(-1, 1)\n",
    "            data_combined = np.concatenate((X, y), axis=1)\n",
    "            data_list.append(data_combined)\n",
    "        dataset = np.concatenate(data_list, axis=0)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data <a id='Load-Data'></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paths to the features and the labels\n",
    "FEATURE_RAW_DIR = \"../../features/raw/\"\n",
    "FEATURE_BAL_PRIOR_DIR = \"../../features/balanced/priori/\"\n",
    "FEATURE_BAL_POSTERIOR_DIR = \"../../features/balanced/posteriori/\"\n",
    "FEATURE_BAL_BOTH_DIR = \"../../features/balanced/both/\"\n",
    "\n",
    "feature_files = {\n",
    "    \"30 MFCC\": \"30mfcc\",\n",
    "    \"12  Chroma\": \"12chroma\",\n",
    "    \"70 CQT\": \"70cqt\",\n",
    "    \"40 RMS\": \"41rms\",\n",
    "    \"40 Zero Crossing Rates\": \"41zcr\",\n",
    "    \"40 Spectral Centroid\": \"41sc\",\n",
    "    \"60 Spectral Bandwidth\": \"61sb\",\n",
    "    \"40 Spectral Rolloff\": \"41sr\",\n",
    "}\n",
    "\n",
    "feature_names = {\n",
    "    \"30 MFCC\": [f\"MFCC {i}\" for i in range(1, 31)],\n",
    "    \"12  Chroma\": [f\"Chroma {i}\" for i in range(1, 13)],\n",
    "    \"70 CQT\": [f\"CQT {i}\" for i in range(1, 71)],\n",
    "    \"40 RMS\": [f\"RMS {i}\" for i in range(1, 42)],\n",
    "    \"40 Zero Crossing Rates\": [f\"Zero Crossing Rates {i}\" for i in range(1, 42)],\n",
    "    \"40 Spectral Centroid\": [f\"Spectral Centroid {i}\" for i in range(1, 42)],\n",
    "    \"60 Spectral Bandwidth\": [f\"Spectral Bandwidth {i}\" for i in range(1, 62)],\n",
    "    \"40 Spectral Rolloff\": [f\"Spectral Rolloff {i}\" for i in range(1, 42)],\n",
    "}\n",
    "names = [\"artifacts\", \"extrahls\", \"murmurs\", \"normals\", \"extrastoles\"]\n",
    "\n",
    "INTERVAL=2\n",
    "SR=4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30 MFCC in ../../features/raw/\n",
      "Features not correlated with the target\n",
      "17\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "17\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(970, 29)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(55, 29)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 29)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 29)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(113, 29)\n",
      "Saving filtered data\n",
      "Processing 12  Chroma in ../../features/raw/\n",
      "Features not correlated with the target\n",
      "1\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "1\n",
      "[-1]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(970, 11)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(55, 11)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 11)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 11)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(113, 11)\n",
      "Saving filtered data\n",
      "Processing 70 CQT in ../../features/raw/\n",
      "Features not correlated with the target\n",
      "33\n",
      "Features highly correlated with each other\n",
      "Removing 32 features\n",
      "32\n",
      "Features to drop\n",
      "65\n",
      "[51 45  9 47 10 44 15  7 56 49 54 13 -1 50 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  8 17\n",
      " 52 55 14  3 11  6  2 43 42  4 46  1 16 53 12 48  5]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(970, 37)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(55, 37)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 37)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 37)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(113, 37)\n",
      "Saving filtered data\n",
      "Processing 40 RMS in ../../features/raw/\n",
      "Features not correlated with the target\n",
      "28\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "28\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(970, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(55, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(113, 40)\n",
      "Saving filtered data\n",
      "Processing 40 Zero Crossing Rates in ../../features/raw/\n",
      "Features not correlated with the target\n",
      "0\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "0\n",
      "[]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(970, 41)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(55, 41)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 41)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 41)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(113, 41)\n",
      "Saving filtered data\n",
      "Processing 40 Spectral Centroid in ../../features/raw/\n",
      "Features not correlated with the target\n",
      "0\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "0\n",
      "[]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(970, 41)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(55, 41)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 41)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 41)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(113, 41)\n",
      "Saving filtered data\n",
      "Processing 60 Spectral Bandwidth in ../../features/raw/\n",
      "Features not correlated with the target\n",
      "61\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "61\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(970, 60)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(55, 60)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 60)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 60)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(113, 60)\n",
      "Saving filtered data\n",
      "Processing 40 Spectral Rolloff in ../../features/raw/\n",
      "Features not correlated with the target\n",
      "38\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "38\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(970, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(55, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(113, 40)\n",
      "Saving filtered data\n",
      "Processing 30 MFCC in ../../features/balanced/priori/\n",
      "Features not correlated with the target\n",
      "19\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "19\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(571, 29)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(369, 29)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 29)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 29)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(381, 29)\n",
      "Saving filtered data\n",
      "Processing 12  Chroma in ../../features/balanced/priori/\n",
      "Features not correlated with the target\n",
      "6\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "6\n",
      "[-1 -1 -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(571, 11)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(369, 11)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 11)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 11)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(381, 11)\n",
      "Saving filtered data\n",
      "Processing 70 CQT in ../../features/balanced/priori/\n",
      "Features not correlated with the target\n",
      "39\n",
      "Features highly correlated with each other\n",
      "Removing 21 features\n",
      "21\n",
      "Features to drop\n",
      "60\n",
      "[51  9 59  7 56 50 -1 49 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  8 52\n",
      " 55 58  3  6  2 57  4  1 53 54 48  5]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(571, 48)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(369, 48)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 48)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 48)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(381, 48)\n",
      "Saving filtered data\n",
      "Processing 40 RMS in ../../features/balanced/priori/\n",
      "Features not correlated with the target\n",
      "2\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "2\n",
      "[-1 -1]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(571, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(369, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(381, 40)\n",
      "Saving filtered data\n",
      "Processing 40 Zero Crossing Rates in ../../features/balanced/priori/\n",
      "Features not correlated with the target\n",
      "0\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "0\n",
      "[]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(571, 41)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(369, 41)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 41)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 41)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(381, 41)\n",
      "Saving filtered data\n",
      "Processing 40 Spectral Centroid in ../../features/balanced/priori/\n",
      "Features not correlated with the target\n",
      "1\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "1\n",
      "[-1]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(571, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(369, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(381, 40)\n",
      "Saving filtered data\n",
      "Processing 60 Spectral Bandwidth in ../../features/balanced/priori/\n",
      "Features not correlated with the target\n",
      "61\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "61\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(571, 60)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(369, 60)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 60)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 60)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(381, 60)\n",
      "Saving filtered data\n",
      "Processing 40 Spectral Rolloff in ../../features/balanced/priori/\n",
      "Features not correlated with the target\n",
      "41\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "41\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(571, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(369, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(534, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(984, 40)\n",
      "dict_keys(['artifacts', 'extrahls', 'murmurs', 'normals', 'extrastoles'])\n",
      "(381, 40)\n",
      "Saving filtered data\n",
      "Processing 30 MFCC in ../../features/balanced/posteriori/\n",
      "Features not correlated with the target\n",
      "16\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "16\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "(2124, 29)\n",
      "(4920, 29)\n",
      "(532, 29)\n",
      "Saving filtered data\n",
      "Processing 12  Chroma in ../../features/balanced/posteriori/\n",
      "Features not correlated with the target\n",
      "4\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "4\n",
      "[-1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "(2124, 11)\n",
      "(4920, 11)\n",
      "(532, 11)\n",
      "Saving filtered data\n",
      "Processing 70 CQT in ../../features/balanced/posteriori/\n",
      "Features not correlated with the target\n",
      "33\n",
      "Features highly correlated with each other\n",
      "Removing 53 features\n",
      "53\n",
      "Features to drop\n",
      "86\n",
      "[45  9 59 37 10 44 15  7 -1 -1 -1 54 13 -1 67 63 19 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 52 17\n",
      " 55 18 65 58 14 66 40 11 35 42 16 12 48  5 47 36 41 56 49  0 50 64 60  4\n",
      " 51 69  8 61 62 38  3  2 43 68 57 46  1 53]\n",
      "Removing features from the dataset\n",
      "(2124, 17)\n",
      "(4920, 17)\n",
      "(532, 17)\n",
      "Saving filtered data\n",
      "Processing 40 RMS in ../../features/balanced/posteriori/\n",
      "Features not correlated with the target\n",
      "0\n",
      "Features highly correlated with each other\n",
      "Removing 32 features\n",
      "32\n",
      "Features to drop\n",
      "32\n",
      "[ 7  4 21 39 23  9  8  1  6 35 10 16 34 40 22 38 33 27  2 17 24 36 15 26\n",
      " 20 18 32  5 25 37 19 28]\n",
      "Removing features from the dataset\n",
      "(2124, 9)\n",
      "(4920, 9)\n",
      "(532, 9)\n",
      "Saving filtered data\n",
      "Processing 40 Zero Crossing Rates in ../../features/balanced/posteriori/\n",
      "Features not correlated with the target\n",
      "0\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "0\n",
      "[]\n",
      "Removing features from the dataset\n",
      "(2124, 41)\n",
      "(4920, 41)\n",
      "(532, 41)\n",
      "Saving filtered data\n",
      "Processing 40 Spectral Centroid in ../../features/balanced/posteriori/\n",
      "Features not correlated with the target\n",
      "1\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "1\n",
      "[-1]\n",
      "Removing features from the dataset\n",
      "(2124, 40)\n",
      "(4920, 40)\n",
      "(532, 40)\n",
      "Saving filtered data\n",
      "Processing 60 Spectral Bandwidth in ../../features/balanced/posteriori/\n",
      "Features not correlated with the target\n",
      "58\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "58\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "(2124, 60)\n",
      "(4920, 60)\n",
      "(532, 60)\n",
      "Saving filtered data\n",
      "Processing 40 Spectral Rolloff in ../../features/balanced/posteriori/\n",
      "Features not correlated with the target\n",
      "28\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "28\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "(2124, 40)\n",
      "(4920, 40)\n",
      "(532, 40)\n",
      "Saving filtered data\n",
      "Processing 30 MFCC in ../../features/balanced/both/\n",
      "Features not correlated with the target\n",
      "18\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "18\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "(2271, 29)\n",
      "(4920, 29)\n",
      "(568, 29)\n",
      "Saving filtered data\n",
      "Processing 12  Chroma in ../../features/balanced/both/\n",
      "Features not correlated with the target\n",
      "1\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "1\n",
      "[-1]\n",
      "Removing features from the dataset\n",
      "(2271, 11)\n",
      "(4920, 11)\n",
      "(568, 11)\n",
      "Saving filtered data\n",
      "Processing 70 CQT in ../../features/balanced/both/\n",
      "Features not correlated with the target\n",
      "22\n",
      "Features highly correlated with each other\n",
      "Removing 53 features\n",
      "53\n",
      "Features to drop\n",
      "75\n",
      "[45  9 59 37 10 44 15  7 54 13 63 67 19 40 -1 -1  5 48 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 52 17 55 18 65 20 58 14 66 11\n",
      " 42 16 12 47 36 41 56 49  0 50 64 60  4 51 69  8 61 62 38  3  2 43 68 57\n",
      " 46  1 53]\n",
      "Removing features from the dataset\n",
      "(2271, 17)\n",
      "(4920, 17)\n",
      "(568, 17)\n",
      "Saving filtered data\n",
      "Processing 40 RMS in ../../features/balanced/both/\n",
      "Features not correlated with the target\n",
      "0\n",
      "Features highly correlated with each other\n",
      "Removing 6 features\n",
      "6\n",
      "Features to drop\n",
      "6\n",
      "[19 21 20 38 39 37]\n",
      "Removing features from the dataset\n",
      "(2271, 35)\n",
      "(4920, 35)\n",
      "(568, 35)\n",
      "Saving filtered data\n",
      "Processing 40 Zero Crossing Rates in ../../features/balanced/both/\n",
      "Features not correlated with the target\n",
      "0\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "0\n",
      "[]\n",
      "Removing features from the dataset\n",
      "(2271, 41)\n",
      "(4920, 41)\n",
      "(568, 41)\n",
      "Saving filtered data\n",
      "Processing 40 Spectral Centroid in ../../features/balanced/both/\n",
      "Features not correlated with the target\n",
      "2\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "2\n",
      "[-1 -1]\n",
      "Removing features from the dataset\n",
      "(2271, 40)\n",
      "(4920, 40)\n",
      "(568, 40)\n",
      "Saving filtered data\n",
      "Processing 60 Spectral Bandwidth in ../../features/balanced/both/\n",
      "Features not correlated with the target\n",
      "61\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "61\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "(2271, 60)\n",
      "(4920, 60)\n",
      "(568, 60)\n",
      "Saving filtered data\n",
      "Processing 40 Spectral Rolloff in ../../features/balanced/both/\n",
      "Features not correlated with the target\n",
      "40\n",
      "Features highly correlated with each other\n",
      "Removing 0 features\n",
      "0\n",
      "Features to drop\n",
      "40\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n",
      "Removing features from the dataset\n",
      "(2271, 40)\n",
      "(4920, 40)\n",
      "(568, 40)\n",
      "Saving filtered data\n"
     ]
    }
   ],
   "source": [
    "# List of folders to process, each corresponding to a different feature set.\n",
    "FOLDERS = [\n",
    "    FEATURE_RAW_DIR,\n",
    "    FEATURE_BAL_PRIOR_DIR,\n",
    "    FEATURE_BAL_POSTERIOR_DIR,\n",
    "    FEATURE_BAL_BOTH_DIR,\n",
    "]\n",
    "\n",
    "# Iterate over each folder in FOLDERS\n",
    "for folder in FOLDERS:\n",
    "    # Iterate over each feature name and corresponding file in feature_files\n",
    "    for feature_name, feature_file in feature_files.items():\n",
    "        print(f\"Processing {feature_name} in {folder}\")\n",
    "\n",
    "        # Construct the full file path for the current feature file\n",
    "        file_path = os.path.join(\n",
    "            folder, f\"full_data_{INTERVAL}s_{SR}hz_{feature_file}.npy\"\n",
    "        )\n",
    "\n",
    "        dataset = []  # Initialize an empty list to store dataset\n",
    "        data = None  # Initialize data to None\n",
    "\n",
    "        # Check if the file path indicates posterior or both types of data\n",
    "        if (\"posterior\" in file_path) or (\"both\" in file_path):\n",
    "            # Load the data from the file and extract the \"train_bal\" subset\n",
    "            data = np.load(file_path, allow_pickle=True).item()\n",
    "            datam = data[\"train_bal\"]\n",
    "\n",
    "            # Separate features (X) and labels (y), then concatenate them into one array\n",
    "            X = datam[\"X\"]\n",
    "            y = datam[\"y\"].reshape(-1, 1)\n",
    "            dataset = np.concatenate((X, y), axis=1)\n",
    "        else:\n",
    "            # Initialize a list to store data from multiple names\n",
    "            data_list = []\n",
    "\n",
    "            # Iterate over each name in names\n",
    "            for name in names:\n",
    "                # Load the data from the file and extract the subset for the current name\n",
    "                data = np.load(file_path, allow_pickle=True).item()\n",
    "                datam = data[name]\n",
    "\n",
    "                # Separate features (X) and labels (y), then concatenate them into one array\n",
    "                X = datam[\"X\"]\n",
    "                y = datam[\"y\"].reshape(-1, 1)\n",
    "                data_combined = np.concatenate((X, y), axis=1)\n",
    "                data_list.append(data_combined)  # Add the combined data to the list\n",
    "\n",
    "            # Concatenate all data from the list into one dataset\n",
    "            dataset = np.concatenate(data_list, axis=0)\n",
    "\n",
    "        # Convert the dataset into a pandas DataFrame with feature names and label\n",
    "        data_df = pd.DataFrame(dataset, columns=feature_names[feature_name] + [\"label\"])\n",
    "\n",
    "        # Identify features that are not correlated with the target\n",
    "        print(\"Features not correlated with the target\")\n",
    "        features_not_correlated = get_features_not_correlated_with_target(\n",
    "            data_df, threshold=0.3\n",
    "        )\n",
    "        print(len(features_not_correlated))\n",
    "\n",
    "        # Identify features that are highly correlated with each other\n",
    "        print(\"Features highly correlated with each other\")\n",
    "        features_highly_correlated = remove_features_highly_correlated(\n",
    "            data_df, threshold=0.85, max_corr_count=6\n",
    "        )\n",
    "        print(len(features_highly_correlated))\n",
    "\n",
    "        # Combine features to drop from both uncorrelated and highly correlated sets\n",
    "        features_to_drop = set(features_not_correlated).union(\n",
    "            set(features_highly_correlated)\n",
    "        )\n",
    "        print(\"Features to drop\")\n",
    "        print(len(features_to_drop))\n",
    "\n",
    "        # Drop the identified features from the dataset\n",
    "        indexes = data_df.columns.get_indexer(features_to_drop)\n",
    "        print(indexes)\n",
    "        print(\"Removing features from the dataset\")\n",
    "        filtered_data = data\n",
    "        # Check if the file path indicates posterior or both types of data\n",
    "        if (\"posterior\" in file_path) or (\"both\" in file_path):\n",
    "            # Load the data from the file and extract the \"train_bal\" subset\n",
    "            for key in filtered_data.keys():\n",
    "                filtered_data[key][\"X\"] = np.delete(\n",
    "                    filtered_data[key][\"X\"], indexes, axis=1\n",
    "                )\n",
    "                print(filtered_data[key][\"X\"].shape)\n",
    "        else:\n",
    "            # Iterate over each name in names\n",
    "            for name in names:\n",
    "                # Load the data from the file and extract the subset for the current name\n",
    "                print(filtered_data.keys())\n",
    "                filtered_data[name][\"X\"] = np.delete(\n",
    "                    filtered_data[name][\"X\"], indexes, axis=1\n",
    "                )\n",
    "                print(filtered_data[name][\"X\"].shape)\n",
    "\n",
    "        print(\"Saving filtered data\")\n",
    "        # Construct the full file path for the current feature file\n",
    "        save_file_path = os.path.join(\n",
    "            folder, f\"full_data_filtered_{INTERVAL}s_{SR}hz_{feature_file}.npy\"\n",
    "        )\n",
    "        np.save(save_file_path, filtered_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the correlation coefficient between the features and the target variable.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
